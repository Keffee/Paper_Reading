# 论文笔记

#### 20250616 还是开始看看LLaMA-Factory叭

#### 20250529 为了改换方向的阅读，不过是乱读
- GRPO简单阅读
  - 价值函数critic估计价值，策略actor决定操作
  - 从PPO开始，off-policy，同时剪切更新率
- CIKM'25, [RankMixer: Scaling Up Ranking Models in Industrial Recommenders]（字节）
  - token输入就比较特殊
    - 输入的特征非常多，所以分了好几个类（T个类），每个类分配一个token的embedding
    - 分配完就是T\*D的embedding，然后分出H个head，然后转置，也就是说现在是H个token，每个dim是T\*D/H，然后分别输入多个头作MoE
  - MoE有很多奇怪的地方，比如使用了ReLU激活，比如使用了全部的专家
  - 最终看来这个融合方法好像很有价值，当然MoE也自不必说很有价值，而且有效降低了flop数
- arxiv'25, [HGCL: Hierarchical Graph Contrastive Learning forUser-Item Recommendation](https://arxiv.org/pdf/2505.19020)（ali，高德）
  - 感想
    - 这里的初始化表征完全没必要做图对比学习，能初始化user/item表征的可太多了
    - 为什么要t-SNE后再聚类？有什么意义？只是为了引入径向划分和角向划分吗？
  - 引言：
    - 将聚类思想应用到GNN表征学习上，提高表征的准确性。就是将item做cluster，user与item的互动关系，可以转换为user与item所在cluster的互动关系，将这个关系增加到GNN的建模过程中。具体的，
      - （1）阶段构建是分成3个阶段，按顺序构建的。先利用跨层对比学习（基于XSimGCL）生成初始用户和物品表示。再将物品节点聚类，构建两层次用户-物品二部图。最后，在原始用户-物品图和用户-聚类物品图上联合优化表示，生成最终推荐。
      - （2）聚类方法先将item的embed通过t-SNE降维，再做聚类。
      - （3）联合训练在最后，原始用户-物品图的推荐、用户-聚类物品图的推荐、原始用户-物品图的跨层对比等3个任务联合训练。
    - 心得：
      - （1）如作者在introduction所说，item聚类既能有效缓解item的稀疏性问题，又能拓展用户互动的范围。互动少的长尾、新item实现了泛化；用户与体育视频item互动，可以上升为与一般娱乐视频互动。
      - （2）有提升空间。本文将item聚类，同时还可以对user做聚类。实现user稀疏问题，也能拓展item互动范围。在其它方面还有一些空间，比如层次聚类。
      - （3）本文的聚类方法挺有趣哈，值得注意。聚类方法是将物品节点表示通过t-SNE降维至二维空间，然后基于径向（ρ）和角度（θ）划分，将位于同一扇区的物品节点聚为一簇，总簇数为ρ*θ。
      - 可信度：离线推荐等级：推荐看看
- arxiv'25, [R^2ec: Towards Large Recommender Models with Reasoning](https://arxiv.org/pdf/2505.16994)（港理工，何向南）
  - 说是让大模型引入推荐一般的思考能力
  - 实际做的事是分成文本头和推荐头，让文本头一直生成，直到生成<answer> token，然后用answer token的输出进行推荐头进行相似度计算
  - 这不还是bigrec？差点被蒙住
- 发现没有，经过这样那样的调研能够发现，所谓tts的瓶颈还是在数据上，pipeline在LLM中早就搭好了，但是数据的缺失限制了这些一切工作
- arXiv'25, [Scaling Transformers for Discriminative Recommendation via Generative Pretraining](https://arxiv.org/pdf/2506.03699)（ali）
  - 可能可以认为CTR和CVR是判别式模型？
  - 我们早有研究，基于transformer的CTR模型就是会有单epoch过拟合的问题
- arXiv'25, [DV365: Extremely Long User History Modeling at Instagram](https://arxiv.org/html/2506.00450v1)(Meta, OpenAI, Instagram)
  - 这东西怎么2023年就上线了，为啥现在写论文（
  - 本文介绍使用离线嵌入获取用户超长序列跨域表征的方法
  - 选择离线嵌入的原因
    - 理论序列长度可能能达70K
    - 用户的长期兴趣是稳定的，不需要大量重复训练
    - 多域/多阶段的长期兴趣都是共享的，所以即使开销大也可以接受
    - 比端到端快
  - 本作中证明了能解决的离线嵌入问题
    - 新鲜度：离线嵌入只捕捉长期兴趣，短期兴趣还是交给平时正常更新的模型捕捉
    - 知识损失和泛化性：用跨域+适配的方式来解决吧
  - 利用长期预测任务来强迫获得长期兴趣（至少预测24小时之后的项目），同时后接很多各种任务，任务们之间用多任务框架融合
  - 处理一个大小为[N,D]的用户嵌入（N为嵌入数量，D为嵌入维度），转化成[D,N]，然后在N维度应用网络，比如自注意力（甚至把N再切分成多个块，然后各自弄）
- arXiv'25, [Revisiting Self-attention for Cross-domain Sequential Recommendation](https://arxiv.org/pdf/2505.21811)
  - 基于自注意力的跨域推荐，说是避免引入显式跨域模块，而是使用基于帕累托边界的思路来更新梯度
  - 没图，文章写的也很难懂
- KDD'25, [Optimizing Recall or Relevance? A Multi-Task Multi-Head Approach for Item-to-Item Retrieval in Recommendation](https://arxiv.org/pdf/2506.06239)(Meta)
  - 协同编码：有效，但是长期兴趣难以建模；语义编码：深度，但是对齐困难
  - 使用样本对来训练模型，首先收集正、负的<trigger, candidate>样本对，正的就是选取序列中的item作为candidate，然后前面的所有的都可以当trigger，负样本就随机
  - 所以经典类似对比损失的文中称为co-engagement loss，当然其实还是内回事儿
  - 同时引入semantic relevance loss，实则为最小化各个样本对的“基于表征的距离”和“基于语义的距离”的KL散度，这个语义距离，顾名思义，是通过多种模态的输入过预训练模型+跨模态对比学习得到的
  - 这个是一个item2item召回，所以看上去略微简单，但是取得了较好的上线效果，并且力压HSTU（毕竟你引入多模态了嘛）
- ICLR'24, [Long-Sequence Recommendation Models Need Decoupled Embeddings]
  - 进行长序列建模的常用操作是先召回topk个item再做transformer，因此其实操作是两个任务，但是这两个任务对同一个embedding来说梯度常常冲突，因此需要解耦embedding
- Towards Large-scale generative ranking(小红书)
  - 虽然看上去还是在整生成式活，但是好像速度上也有很大提升（回头看看）
- MTGR为什么基本不用考虑效率问题？有一个技术文档可以去看看
- arXiv'25, [MTGR: Industrial-Scale Generative Recommendation Framework in Meituan](https://arxiv.org/pdf/2505.18654)
  - 过去的做法，user behavior做K和V，Target item做Q，然后过注意力，再和context和user profile融合；然后进化为之前的注意力不变，但是context、user profile做Q也过一次注意力，然后两个注意力的结果融合
  - 全部改用HSTU作encoder的架构，输入三大块（当然内部也分很多token），user profile各自编码、行为序列每个token都是id和side info编码的融合、曝光样本里是target id和对应side info和交叉特征和时空等context
  - 动态掩码，因为target只能看到在它出现之前的实时行为
  - 剩下的都是大量的工程优化，目的是加速
  - 最终在美团外卖全量
- arXiv'25, [TransAct V2: Lifelong User Action Sequence Modeling on Pinterest Recommendation](https://arxiv.org/pdf/2506.02267)(Pinterest)
- 长序列的总结
  - 随着用户规模不断增大，序列不断变长，原有的两阶段序列建模范式逐渐向一阶段序列建模范式转变，以此实现无损的、端到端的建模方式。
  - 依托类Transformer架构（Transformer、HSTU等），工业界从数据组织形式（DLRM特征、item-action等）、效率优化等方面入手，探索生成式推荐模型在实际工业场景的落地。
  - 生成式推荐模型的发展，并不意味着从DLRM等传统模型中获得的经验失去了价值。相反，如MTGR 和LONGER等模型的成功，正是对DLRM 框架中特征交叉、因果注意力机制等思想的延续与演化。
  - 同时,这一发展趋势也不意味着已有的生成式方案就是最优解，例如，HSTU的数据组织存在冗长等问题。还是有许多问题值得去解决和探索的。

#### Data Augmentation
- arXiv '25, [Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation](https://arxiv.org/pdf/2503.22675)(ReaRec)(Ali)(Gaoling)(2025.3.28)
  - 和我们的想法非常类似，都是多生成几个token（思维链），区别是他们使用的是上一个推理结果的隐层加上[推理]位置编码来获得的
  - 两个部分，ProgressiveReasoningLearning (PRL)和EnsembleReasoningLearning (ERL)
  - ERL，如何直接改进这种监督学习过程？：
    - 直接的rec loss就是在我们这种多生成几个token的基础上，继续用最后一个token的隐层来进行推理，但是这种方法有两个问题，首先是推理的中间过程缺乏监督，可能会退化；其次是任务差距过大
    - 改进策略1：对推理链路上的每个item都采取一次loss计算，最终相加，但是问题是这样低效并且可能会引导推理过程多次产生重复解
    - 改进策略2：避免重复解，引入KL散度，让模型推理过程尽可能有区别。最终结果就是逐步$L_{rec}+\alpha L_{KL}$
    - 这样就可以在推理阶段使用平均池化聚合所有隐藏状态了
  - PRL，能否使用渐进的学习，引导推理链走向用户真实分布？：
    - 引入温度，靠前的序列温度值大，靠后的温度值小，这样一开始的探索会比较广泛，最终会逐渐减小探索力度。
    - 但是这样推理可能会产生错误的累积（什么强化学习必备问题），解决方法是在输入TRM之前引入噪声，然后对比学习（计算当前加了噪声之后TRM推出来的隐层与正常情况下TRM推出来的隐层之间的对比，拉近同个item的不同表征，拉远正常情况下同batch的其他同为第k个位置的表征
  - 与SASRec、Bert4Rec为代表的序列模型和UniSRec和MoRec为代表的text模型结合效果都明显提升
  - user历史序列越长效果越不显著；item越popular效果越不显著
  - 过度推理导致了过度思考，所以自适应很有必要（现在在这几个Amazon数据集上都是推理深度2左右就最好）
  - 按照消融实验，KL散度和对比学习太重要了
- arXiv '25, [LLMSeR: Enhancing Sequential Recommendation via LLM-based Data Augmentation](https://arxiv.org/pdf/2503.12547)(LLMSeR)
  - 解决长尾问题，以及现有数据增强中的幻觉问题
  - 首先倒着训练一个SRS，然后这个SRS就可以用来生成“伪”历史序列
  - 使用LLM来判断生成的“伪”历史的质量，当然了，感觉这个方法有点蹭LLM
  - 训练过程中，引入权重衰减来降低增强方法对已经很丰富的序列的影响。
  - 与我们的区别：我们的方法使用了统一的SRS，任务统一，而且我们更多的不是缓解长尾问题，而是解决数据中正样本稀疏的问题。
- SIGIR '21, [Augmenting Sequential Recommendation with Pseudo-Prior Items via Reversely Pre-training Transformer](https://arxiv.org/pdf/2105.00522)(ASReP)(PhilipS Yu)
  - LLMSeR的灵感来源
  - 从右到左训练一个transformer，从而生成伪先验物品
  - 最后对同一个transformer进行从左到右finetune，获得性能提升的结果
- TKDE '21, [Improving Sequential Recommendations via Bidirectional Temporal Data Augmentation with Pre-training](https://arxiv.org/pdf/2112.06460)(BARec)(PhilipS Yu)
  - ASPeP的扩展，解决负向训练正向微调时间不一致性的问题
  - 在预训练学习生成负向内容的时候，进行一次负向预测就进行一次正向预测，Loss相加
  - 新生成的序列的熵小于原有序列，可能带来过拟合风险，因此，我们引入KL散度，来衡量基于原始序列生成的预测embedding和基于增强序列生成的预测embedding的分布差异，也作为一个loss加到微调loss中
- arXiv '21, [Contrastive self-supervised sequential recommendation with robust augmentation](https://arxiv.org/pdf/2108.06479)(CoSeRec)(PhilipS Yu)
  - 扰动序列（插入/删除/交换/替换/截断），其中替换和插入是和上下文相关的
  - 使用统计方法计算item相似度，但是整体还是比较简单的（ItemCF-IUF，一种基于交互此item的user数的统计量），另一种计算相似度的方式就是基于embedding相似度了（前部分epoch使用统计方法，后面则使用embedding方法）
  - 随机采样两种增强方法再做对比学习（感觉一般）
  - 具体loss是不同增强方法之间的NT-Xent loss，和正常推荐结果的推荐loss
- Few-shot intent detection via contrastive pre-training and fine-tuning
  - 解决语言模型的少样本意图检测问题
  - 自监督对不同掩码的同一语句意图拉近、监督地拉近相同意图句子推远不同意图句子
- IEEE Access '25, [SURE: Session-based Uninteresting Item Removal for Enhanced Recommendations](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10916647)(SURE)
  - 目标是解决短序列中噪声和信号不足问题
  - 使用ARM算法筛选可用数据
  - 类似ASReP，倒序训练transformer来扩增历史数据
- A deep learning based trust- and tag-aware recommender system
- Time interval aware self-attention for sequential recommendation
- Your Causal Self-Attentive Recommender Hosts a Lonely Neighborhood
- TD3: Tucker Decomposition Based Dataset Distillation Method for Sequential Recommendation
- Explicit and Implicit Counterfactual Data Augmentation for Sequential Recommendation
- ADARec: An Adaptive Data Augmentation Framework for Sequence Recommendation
- CSLP: Collaborative Solution to Long-Tail Problem and Popularity Bias in Sequential Recommendation
- Reliable Data Augmented Contrastive Learning for Sequential Recommendation
- Rss: Effective and efficient training for sequential recommendation using recency sampling

#### Data Centric
- arXiv '24, [A Survey on Data-Centric Recommender System](https://arxiv.org/pdf/2401.17878)
  - Data Incompleteness 数据不完整性
    - Missing user profiles
      - SIGIR '20, [Joint Item Recommendation and Attribute Inference: AnAdaptive Graph Convolutional Network Approach](https://arxiv.org/pdf/2005.12021)(AGCN)
        - 通过多任务联合训练，同时进行偏好预测和缺失属性的推断
    - Limited item attributes
      - KDD '19, [Enhancing Collaborative Filtering with Generative Augmentation](https://dl.acm.org/doi/pdf/10.1145/3292500.3330873)(AugCF)
        - 基于gan的原理来生成和鉴别，但是这样训练肯定很难
        - 利用Gumbel-Softmax来克服分类的离散化问题
      - WSDM '23, [Disentangled Negative Sampling for Collaborative Filtering](https://dl.acm.org/doi/pdf/10.1145/3539597.3570419)(DENS)
        - 传统负采样：引入流行度加权负采样/对难负样本过采样
        - 负采样粒度可以更细，将物品拆分成多个因素
        - WSDM真是故事性强强强
      - CIKM '23, [Diffusion Augmentation for Sequential Recommendation](https://arxiv.org/pdf/2309.12858)(DiffuASR)(Huawei)
        - 利用diffusion生成高质量伪数据来解决数据稀疏性和长尾用户问题
        - 设计适合序列生成的diffusion来进行生成
    - Sparse user-item interactions
    - Inadequate contextual information
  - Data Noise
    - Redundant data 数据冗余
      - 模型蒸馏：或许这也是个普遍做法？利用一个模型
      - NeruIPS '22, [Infinite Recommendation Networks: A Data-Centric Approach](https://arxiv.org/pdf/2206.02626)(DISTILL-CF)
        - 这个工作的一半是一种推荐模型，所以我们不讨论
        - 数据蒸馏：sample user，利用模型来retrival item（这一步利用gumbel softmax所以可微，用这个item来训练，算是个普通做法？
    - Inconsistent data 数据不一致
      - WSDM '21, [Denoising Implicit Feedback for Recommendation](https://arxiv.org/pdf/2006.04153)(R-CE)
        - 假阳性问题很大，而且很常见
        - 一个观点：假阳性样本更难训练
      - WWW '23, [A Self-Correcting Sequential Recommender](https://arxiv.org/pdf/2303.02297)(STEAM)[code](https://github.com/TempSDU/STEAM)
        - 分为底层编码器、item修正器和推荐器
        - 修正器自监督地学习删除多余item和找寻被删除的item，本质上为每一个item都判断{保留, 删除, 插入}（如果是插入，就从当前位置开始逆序生成）
      - arXiv '23, [Label Denoising through Cross-Model Agreement](https://arxiv.org/pdf/2308.13976)(DeCA)(Feng Fuli)
        - 一个观点：对于错误的样本，不同模型的结果差异会比较大，但是对于正确的样本，不同模型的结果差异比较小
        - 利用辅助模型和KL散度、数据观测的最大化似然来帮助目标模型更好地学习真实标签分布
    - Spam or fake data
  - Data Bias
    - Shifts in user preferences
      - 存在六大偏好
        - 特征偏好
        - 特征值偏好：项目存在特殊性
        - 社会影响偏好
        - 时间动态偏好
        - 条件偏好：项目与值的依赖关系
        - 用户项目偏差：某些用户倾向于给出更高评价
      - WWW '23, [Invariant Collaborative Filtering to Popularity Distribution Shif](https://arxiv.org/pdf/2302.05328)(InvCF)
        - 希望能够不随时间变化地找到用户的偏好表示
        - 先正常用户编码
        - 利用历史交互次数进行流行度编码，把交互数量输进去编码成d维向量(?)
        - 利用这种方法，我们能拼出物品表征（直接把上面两个拼起来）
        - 基于上面这种流行度生成方法，我们可以获得很多时刻的流行度，可以分别替换此刻的流行度输入来增强我们的表示
        - 将流行度表征和正常表征的相关性距离loss也作为一个loss
    - Changes in item Popularity
      - WSDM '20, [Unbiased Recommender Learning from  Missing-Not-At-Random Implicit Feedback](https://arxiv.org/pdf/1909.03601)(MNAR)
        - 利用逆倾向得分来对训练实例的损失重新加权
        - 具体公式太复杂，大致上是想办法计算出倾向得分，然后获得逆倾向得分，然后用它和1-它来给损失加权
      - WWW '21, [Disentangling User Interest and Conformity for  Recommendation with Causal Embedding](https://arxiv.org/pdf/2006.11011)(DICE)
        - 针对流行度，可以分开优化两个embedding，这两个embedding分别对应流行度点击和兴趣点击，因此流行度点击针对高流行度点击正优化，低流行度点击负优化，兴趣点击针对低流行度点击正优化，额外增加流行度建模和兴趣建模的差异loss（差别越大越好），但是最终还要融合在一起再根据点击反馈来优化（茅盾文学奖）
- arXiv '23, [Data-centric Artificial Intelligence: A Survey](https://arxiv.org/pdf/2303.10158)
  - 三大任务：训练数据开发、推理数据开发、数据维护
  - 样本如何选择：基于统计（data信息）、基于模型性能（类强化学习）、基于长袜知识
- ICLR '25, [Towards Realistic Data Generation for Real-World Super-Resolution](https://arxiv.org/pdf/2406.07255)(RealDGen)
  - CV的工作，将低分辨率图片进行基于Diffusion的方法进行超分的方法
  - 大部分内容在讲Diffusion
  - 使用两个模块：Deg是降质器，Cont是特征提取器，分别单独训练
  - 实际使用中，目标真实图像的降质结果和未配对的的图像的提取结果进行结合，从而提升表征的泛化性。
- ICLR '25, [Combatting Dimensional Collapse in LLM Pre-Training Data via Submodular File Selection](https://openreview.net/pdf?id=f4gF6AIHRy)(DiSF)
  - 更接近增量微调过程中的问题，对于新进行训练的数据，很容易出现维度崩塌，通用性能下降，因此尽可能选择增强多样性的数据
  - 选取高价值样本，我们使用最小化协方差矩阵的Frobenius范数（弗罗贝尼乌斯范数）来选择更有多样性的样本
  - 首先获取文本特征，然后计算特征协方差矩阵和这个范数，然后贪心算法选取，使用γ-弱次模优化问题分析这个的近似最优解
  - 引入假设：增益差异的上界（Bounded Gain Difference），限制了增益变化的范围，使得在不同集合之间进行比较时，增益的变化不会过于剧烈；引入假设：平均效用的上界（Bounded Average Utility），确保了集合的效用不会无限增长，从而使得优化问题在理论上更容易分析。引入两个假设使得模型可以视作一个γ-弱次模优化问题从而贪心优化
- ICLR '25, [Weak-to-Strong Generalization Through the Data-Centric Lens](https://arxiv.org/pdf/2412.03881)
    - 算法从弱到强的泛化（一个弱模型指导一个强模型）存在，本文研究数据中的什么方面能够让这种泛化成为可能。
    - 这篇文章的related work有好多关于data centric的东西
    - 认为一个数据集中存在两种数据，简单的和困难的，弱模型适合简单数据，强模型适合困难数据，当然这两种数据存在重叠，我们希望找到尽可能多的这种重叠数据，从而训练一个弱到强模型来从中学习生成更适合强模型训练的困难数据
    - 认为弱模型在难数据上置信度较低，

#### Data Centric，从CVPR中找方法：
Efficient Model Stealing Defense with Noise Transition Matrix Poster Session 6 & Exhibit Hall
高效的模型盗窃防御与噪声转移矩阵 海报会议 6 & 展览厅

HOIAnimator: Generating Text-prompt Human-object Animations using Novel Perceptive Diffusion Models Poster Session 1 & Exhibit Hall
HOIAnimator：使用新颖的感知扩散模型生成文本提示的人物-物体动画 海报会议 1 & 展览厅

LowRankOcc: Tensor Decomposition and Low-Rank Recovery for Vision-based 3D Semantic Occupancy Prediction Poster Session 3 & Exhibit Hall
LowRankOcc：基于视觉的 3D 语义占用预测的张量分解和低秩恢复 海报会议 3 & 展览厅

Overcoming Generic Knowledge Loss with Selective Parameter Update Poster Session 5 & Exhibit Hall
通过选择性参数更新克服通用知识丧失 海报会议 5 & 展览厅

Lane2Seq: Towards Unified Lane Detection via Sequence Generation Poster Session 4 & Exhibit Hall
Lane2Seq: 通过序列生成实现统一车道检测 海报会议 4 & 展览厅

CorrMatch: Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation Poster Session 1 & Exhibit Hall
CorrMatch: 通过相关匹配进行标签传播的半监督语义分割 海报会议 1 & 展览厅

CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive Self-Supervised Transformers Poster Session 5 & Exhibit Hall
CuVLER: 通过全面自监督变换器增强无监督物体发现 海报会议 5 & 展览厅

Diffusion Model Alignment Using Direct Preference Optimization Poster Session 2 & Exhibit Hall
扩散模型对齐使用直接偏好优化 海报会议 2 & 展览厅

Check Locate Rectify: A Training-Free Layout Calibration System for Text-to-Image Generation Poster Session 2 & Exhibit Hall
检查定位校正：一种无训练的布局校准系统，用于文本到图像生成 海报会议 2 & 展览厅

Boosting Self-Supervision for Single-View Scene Completion via Knowledge Distillation Poster Session 3 & Exhibit Hall
通过知识蒸馏提升单视图场景补全的自我监督 海报会议 3 & 展览厅

CrossKD: Cross-Head Knowledge Distillation for Object Detection Poster Session 4 & Exhibit Hall
CrossKD: 跨头知识蒸馏用于目标检测 海报会议 4 & 展览厅

Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning Poster Session 6 & Exhibit Hall
用新数据复活旧类别以实现无示例的持续学习 海报会议 6 & 展览厅

DIEM: Decomposition-Integration Enhancing Multimodal Insights Poster Session 6 & Exhibit Hall
DIEM: 分解-集成增强多模态洞察 海报会议 6 & 展览厅

PromptKD: Unsupervised Prompt Distillation for Vision-Language Models Poster Session 6 & Exhibit Hall
PromptKD: 无监督提示蒸馏用于视觉-语言模型 海报会议 6 & 展览厅

Domain Gap Embeddings for Generative Dataset Augmentation Poster Session 6 & Exhibit Hall
生成数据集增强的领域间隙嵌入 海报会议 6 & 展览厅

RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization Poster Session 2 & Exhibit Hall
RealCustom: 针对实时开放领域文本到图像定制的真实文本词汇缩小 海报会议 2 & 展览厅

Discover and Mitigate Multiple Biased Subgroups in Image Classifiers Poster Session 3 & Exhibit Hall
发现和缓解图像分类器中的多个偏见子群 论文海报会议 3 & 展览厅

Balancing Act: Distribution-Guided Debiasing in Diffusion Models Poster Session 2 & Exhibit Hall
平衡行为：扩散模型中的分布引导去偏见 海报会议 2 & 展览厅

FMA-Net: Flow-Guided Dynamic Filtering and Iterative Feature Refinement with Multi-Attention for Joint Video Super-Resolution and Deblurring Poster Session 1 & Exhibit Hall
FMA-Net：基于流的动态过滤和多重注意力的迭代特征精炼，用于联合视频超分辨率和去模糊 海报会议 1 & 展览厅

DIOD: Self-Distillation Meets Object Discovery Poster Session 1 & Exhibit Hall
DIOD: 自我蒸馏与物体发现 海报会议 1 & 展览厅

MAFA: Managing False Negatives for Vision-Language Pre-training Poster Session 6 & Exhibit Hall
MAFA: 管理视觉-语言预训练中的假阴性 海报会议 6 & 展览厅

RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models Poster Session 2 & Exhibit Hall
RAVE：随机噪声洗牌用于快速且一致的视频编辑与扩散模型 海报会议 2 & 展览厅

Stable Neighbor Denoising for Source-free Domain Adaptive Segmentation Poster Session 5 & Exhibit Hall
源无关领域自适应分割的稳定邻域去噪 海报会议 5 & 展览厅

In-distribution Public Data Synthesis with Diffusion Models for Differentially Private Image Classification Poster Session 3 & Exhibit Hall
使用扩散模型进行差分隐私图像分类的分布内公共数据合成 海报会议 3 & 展览厅

Don’t Drop Your Samples! Coherence-Aware Training Benefits Conditional Diffusion Poster Session 2 & Exhibit Hall
不要丢弃你的样本！一致性意识训练有利于条件扩散 海报会议 2 & 展览厅

D3still: Decoupled Differential Distillation for Asymmetric Image Retrieval Poster Session 4 & Exhibit Hall
D3still: 解耦差分蒸馏用于非对称图像检索 海报会议 4 & 展览厅

DetDiffusion: Synergizing Generative and Perceptive Models for Enhanced Data Generation and Perception Poster Session 2 & Exhibit Hall
DetDiffusion: 协同生成模型和感知模型以增强数据生成和感知 海报会议 2 & 展览厅

LAN: Learning to Adapt Noise for Image Denoising Poster Session 6 & Exhibit Hall
LAN: 学习适应噪声以进行图像去噪 海报会议 6 & 展览厅

SwiftBrush: One-Step Text-to-Image Diffusion Model with Variational Score Distillation Poster Session 2 & Exhibit Hall
SwiftBrush：一种具有变分评分蒸馏的一步文本到图像扩散模型 海报会议 2 & 展览厅

Aligning Logits Generatively for Principled Black-Box Knowledge Distillation Poster Session 5 & Exhibit Hall
生成性对齐 Logits 以实现原则性的黑箱知识蒸馏 海报会议 5 & 展览厅

EgoGen: An Egocentric Synthetic Data Generator Poster Session 4 & Exhibit Hall
EgoGen: 一种自我中心的合成数据生成器 海报会议 4 & 展览厅

Class Incremental Learning with Multi-Teacher Distillation Poster Session 6 & Exhibit Hall
多教师蒸馏的类增量学习 海报会议 6 & 展览厅

Scaling Laws of Synthetic Images for Model Training ... for Now Poster Session 2 & Exhibit Hall
合成图像的缩放法则用于模型训练 ... 目前海报会议 2 & 展览厅

Logarithmic Lenses: Exploring Log RGB Data for Image Classification Poster Session 4 & Exhibit Hall
对数透镜：探索用于图像分类的对数 RGB 数据 海报会议 4 & 展览厅

Language-driven Object Fusion into Neural Radiance Fields with Pose-Conditioned Dataset Updates Poster Session 2 & Exhibit Hall
基于语言的物体融合到神经辐射场中，带有姿态条件的数据集更新 海报会议 2 & 展览厅

Learning Vision from Models Rivals Learning Vision from Data Poster Session 4 & Exhibit Hall
从模型中学习视觉与从数据中学习视觉的竞争 海报会议 4 & 展览厅

Taming Mode Collapse in Score Distillation for Text-to-3D Generation Poster Session 2 & Exhibit Hall
驯服文本到 3D 生成中的评分蒸馏模式崩溃 海报会议 2 & 展览厅

DeiT-LT: Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets Poster Session 5 & Exhibit Hall
DeiT-LT: 蒸馏重返长尾数据集上的视觉变换器训练 海报会议 5 & 展览厅

Fully Exploiting Every Real Sample: SuperPixel Sample Gradient Model Stealing Poster Session 6 & Exhibit Hall
充分利用每个真实样本：超像素样本梯度模型盗取海报会议 6 及展览厅

Ranking Distillation for Open-Ended Video Question Answering with Insufficient Labels Poster Session 3 & Exhibit Hall
开放式视频问答的排名蒸馏方法，标签不足的海报会议 3 及展览厅

Finding Lottery Tickets in Vision Models via Data-driven Spectral Foresight Pruning Poster Session 4 & Exhibit Hall
通过数据驱动的光谱前瞻修剪在视觉模型中寻找彩票票据 海报会议 4 & 展览厅

Gradient Reweighting: Towards Imbalanced Class-Incremental Learning Poster Session 4 & Exhibit Hall
梯度重加权：朝向不平衡的类增量学习 海报会议 4 & 展览厅

D^4: Dataset Distillation via Disentangled Diffusion Model Poster Session 2 & Exhibit Hall
D^4: 数据集蒸馏通过解耦扩散模型 海报会议 2 & 展览厅

#### Data Centric，从ICLR中找方法：
- Data generation
  - Khan, Z., Stengel-Eskin, E., Cho, J., & Bansal, M. (2024). DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback (No. arXiv:2410.06215). arXiv. https://doi.org/10.48550/arXiv.2410.06215
  - **Peng, L., Li, W., Pei, R., Ren, J., Xu, J., Wang, Y., Cao, Y., & Zha, Z.-J. (2025). Towards Realistic Data Generation for Real-World Super-Resolution (No. arXiv:2406.07255). arXiv. https://doi.org/10.48550/arXiv.2406.07255**
  - Reizinger, P., Bizeul, A., Juhos, A., Vogt, J. E., Balestriero, R., Brendel, W., & Klindt, D. (2024). Cross-Entropy Is All You Need To Invert the Data Generating Process (No. arXiv:2410.21869). arXiv. https://doi.org/10.48550/arXiv.2410.21869
    - 一个理论分析，来证明交叉熵最小化对分类任务的有效性
  - Wang, Z., Li, J., Hong, Y., Li, S., Li, K., Yu, S., Wang, Y., Qiao, Y., Wang, Y., Bansal, M., & Wang, L. (2024). Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel (No. arXiv:2412.08467). arXiv. https://doi.org/10.48550/arXiv.2412.08467
    - 希望为导航领域生成高质量的数据集
    - 迭代训练导航器和生成器，其中导航器的结果会用来确定哪些数据属于适合生成器的高质量数据，从而便于生成器下一步训练
- Data attribution
  - DATA, T. P. (不详). GENERALIZATION VS MEMORIZATION: TRACING LANGUAGE MODELS’CAPABILITIES BACK TO PRETRAINING DATA. 取读于 2025年2月16日, 从 https://openreview.net/forum?id=IQxBDLmVpT
    - 深入分析预训练数据和大模型生成结果之间的关系
    - 这可能是我们日后分析数据质量的一个方法，但是现在似乎还没有很好的作用
  - Isonuma, M., & Titov, I. (2024). What’s New in My Data? Novelty Exploration via Contrastive Generation (No. arXiv:2410.14765). arXiv. https://doi.org/10.48550/arXiv.2410.14765
    - 试图在不访问数据集的情况下进行新奇度检测(Novelty Exploration)
    - 因为不能使用数据集，所以对数据集微调过后的语言模型的生成结果进行检测
    - 根据微调后的模型和原有模型的文本徐咧x的对数对数概率差计算对比分数
  - Khaddaj, A., Engstrom, L., & Madry, A. (不详). Small-to-Large Generalization: Data Influences Models Consistently Across Scale. 取读于 2025年2月16日, 从 https://openreview.net/forum?id=GsBohvopf6
    - 探究数据的选择如何影响大模型的训练
  - Lin, X., Xu, X., Ng, S.-K., & Low, B. K. H. (不详). Top-m Data Values Identification. The Thirteenth International Conference on Learning Representations. 取读于 2025年2月16日, 从 https://openreview.net/forum?id=lOfuvmi2HT
    - 一种数据选择方法，改进基于多臂老虎机的数据选择方法
  - Sun, C., Aksitov, R., Zhmoginov, A., Miller, N. A., Vladymyrov, M., Rueckert, U., Kim, B., & Sandler, M. (不详). How new data pollutes LLM knowledge and how to dilute it. Neurips Safe Generative AI Workshop 2024. 取读于 2025年2月16日, 从 https://openreview.net/forum?id=LA0ep4kKD0
    - 了解新文本如何改变大语言模型的知识，通过研究学习前token概率来预测学习后的启发作用
  - Wang, J. T., Mittal, P., Song, D., & Jia, R. (2024). Data Shapley in One Training Run (No. arXiv:2406.11011). arXiv. https://doi.org/10.48550/arXiv.2406.11011
    - 一种高效的Data Shapley算法，使用了多种近似和share算法
  - Wang, J. T., Song, D., Zou, J., Mittal, P., & Jia, R. (2024). Capturing the Temporal Dependence of Training Data Influence (No. arXiv:2412.09538). arXiv. https://doi.org/10.48550/arXiv.2412.09538
    - 在现代算法，尤其是随机算法和多阶段课程算法中，数据的顺序也有影响，我们这里提出一种方法来找到合适的输入数据的顺序
- Data selection
  - **DATA, T. (不详). COMBATTING DIMENSIONAL COLLAPSE IN LLM PRE-TRAINING DATA VIA DIVERSIFIED FILE SELECTION. 取读于 2025年2月16日, 从 https://openreview.net/forum?id=f4gF6AIHRy**
    - 更接近增量微调过程中的问题，对于新进行训练的数据，很容易出现维度崩塌，通用性能下降，因此尽可能选择增强多样性的数据
  - **Shin, C., Cooper, J., & Sala, F. (2024). Weak-to-Strong Generalization Through the Data-Centric Lens (No. arXiv:2412.03881). arXiv. https://doi.org/10.48550/arXiv.2412.03881**
    - 算法从弱到强的泛化（一个弱模型指导一个强模型）存在，本文研究数据中的什么方面能够让这种泛化成为可能。
    - 这篇文章的related work有好多关于data centric的东西
  - Thrush, T., Potts, C., & Hashimoto, T. (2024). Improving Pretraining Data Using Perplexity Correlations (No. arXiv:2409.05816). arXiv. https://doi.org/10.48550/arXiv.2409.05816
    - 希望找到一种办法，不进行预训练就选出高质量的预训练数据
    - 是把“利用该数据训练出的LLM作为关键信息来反推预训练数据的作用”
  - Zhang, C., Zhong, H., Zhang, K., Chai, C., Wang, R., Zhuang, X., Bai, T., Qiu, J., Cao, L., Fan, J., Yuan, Y., Wang, G., & He, C. (2024). Harnessing Diversity for Important Data Selection in Pretraining Large Language Models (No. arXiv:2409.16986). arXiv. https://doi.org/10.48550/arXiv.2409.16986
    - 目的是找到适合预训练大语言模型的的数据，使用影响函数和

#### CTR有没有scaling law呢？
- ICML '25, [Wukong: Towards a Scaling Law for Large-Scale Recommendation](https://arxiv.org/pdf/2403.02545)
  - 同样是提到现在的大规模CTR存在问题：更多的提升专注在embedding表部分，对于模型交互并没有什么改进，但是提升embedding表大小似乎没太大效果
  - 实际网络层是拼合的FMBlock和Linear Compress Block，然后过MLP+残差，这算一个Wukong块，进行堆叠
- KDD '23, [MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction](https://arxiv.org/pdf/2308.01737.pdf)
  - 一个模型无关的CTR特征角度的预训练框架
  - 两个预训练任务
    - 随机破坏特征，然后如果有f个field就使用f套MLP对各自field内的被破坏特征进行预测，预测被破坏（其实就是被替换）的特征原本的特征，使用NCE loss来进行优化
    - 随机破坏特征，然后对每个特征都进行预测，预测第f个field被破坏的概率，使用BCE loss进行优化

#### KDD25失利的补充阅读
- ICML '20, [Differentiable Product Quantization for End-to-End Embedding Compression](https://arxiv.org/pdf/1908.09756)(DPQ)[code](https://github.com/chentingpc/dpq_embedding_compression)
  - 可微量化模块
  - PQ操作是切成D块，每一块在K个code中选一个
- SIGIR '23, [AutoDPQ: Automated Differentiable Product Quantization for Embedding Compression](https://dl.acm.org/doi/pdf/10.1145/3539618.3591953)
  - 相比DPQ，增加了AutoML过程，使得能够搜索最合适的K和D
  - 这一过程需要额外的训练时间
- arXiv '20, [AutoEmb: Automated Embedding Dimensionality Search in Streaming Recommendations](https://arxiv.org/pdf/2002.11252)
  - 自适应决定每个特征的嵌入层维度（用来解决低频信号信息少的问题）
  - 同样使用AutoML技巧
- arXiv '21, [CLICK-THROUGH RATE PREDICTION WITH AUTO-QUANTIZED CONTRASTIVE LEARNING](https://arxiv.org/pdf/2109.13921)(AQCL)(ALI)(DAMO)
  - 改进ICL算法，把原本的自监督对比学习改成了聚类的自监督对比学习，同一用户实例与实例相似，同一聚类中大家尽可能靠近中心
  - 目标是解决冷启动问题，提升效果
- NeurIPS '24, [Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems](https://arxiv.org/pdf/2305.12102)(Deep Mind)
  - 通过复用嵌入，从每个组成特征分解成组件，从而允许模型区分特征。
  - 简单、缓解低延迟问题，同时提升指标，解决搜推问题
  - 是一种改进的哈希量化
- NeurIPS '23, [Clustering the sketch: dynamic compression for embedding tables](https://proceedings.neurips.cc/paper_files/paper/2023/file/e468a76212a58c1af94a3d235151944a-Paper-Conference.pdf)(CCE)
  - 使用码本量化+哈希嵌入，从而两全其美：码本量化压缩率高，而哈希方法动态更新
  - 按照稳重的说法，是一种“在不知道嵌入”的情况下进行量化的方法
  - 这篇文章讲解各种量化方法还蛮详细的
- Recsys '23, [Efficient Data Representation Learning in Google-scale Systems](https://dl.acm.org/doi/pdf/10.1145/3604915.3608882)
  - 需要考虑高效高质量的数据表示
  - 多尺度统一嵌入学习高质量嵌入、深度交叉网络学习有效的特征交叉
  - 或许可以认为传统的建模模型可以被分为表征部分和建模部分，现在在建模部分做的很多，但是在表征部分相当简单
  - 使用统一嵌入提升了DCNv2的效果，但是具体是怎么提升的？文章没有明写，给出了tf2的代码，但是先不看了吧
- WSDM '24, [Budgeted embedding table for recommender systems](https://arxiv.org/pdf/2310.14884)(BET)
  - 提出一种预算嵌入表，便于搜索所有用户和项目的嵌入大小，从而适配轻量级嵌入
  - 一种特殊的强化学习框架，但是强化学习的生成无法保证嵌入绝对满足要求，并且如果逐个特征（部分特征）进行优化的话，速度比较慢
  - 属于一个搜索策略，并且给出一个预测网络来评估动作可能的成本
- NeruIPS '22, [The trade-offs of model size in large recommendation models : 100GB to 10MB Criteo-tb DLRM model](https://proceedings.neurips.cc/paper_files/paper/2022/file/dbae915128892556134f1c5375855590-Paper-Conference.pdf)
- MLSys '22, [Random Offset Block Embedding (ROBE) for compressed embedding tables in deep learning recommendation systems](https://proceedings.mlsys.org/paper_files/paper/2022/file/1eb34d662b67a14e3511d0dfd78669be-Paper.pdf)
- MLSys '21, [TT-Rec: Tensor Train Compression for Deep Learning Recommendation Models](https://arxiv.org/pdf/2101.11714)

#### tokenizer
- 可以预见地，早期许多工作其实直接用了item_name来表示
  - arXiv '23, [GenRec: Large Language Model for Generative Recommendation](https://arxiv.org/pdf/2307.00457)(GenRec)
- SIGIR '24, [IDGenRec: LLM-RecSys Alignment with Textual ID Learning](https://arxiv.org/pdf/2403.19021)(Rutgers University)[code](https://github.com/agiresearch/IDGenRec)
  - 用重生成文本来表示LLM推荐系统中的item比较好
  - 要求
    - ID生成器应当理解冗长文本：使用T5进行
    - 生成的ID要短而唯一：提出多样化ID生成方法
    - ID生成器和推荐器间如何协作：异步训练两个LLM（另一个也是T5）
  - ID生成器：将较长的元信息压缩为较短的token集合
    - 基于多束搜索(DBS)
  - 基本推荐器：预测next item的对应文本ID
    - 使用约束序列解码策略(constrained sequence decoding strategy)生成ID，具体而言是当前缀token确定时，后面的token只能从存在对应item的token里选取
  - 异步训练
    - 训练基本推荐器：利用ID生成器预生成，然后使用教师训练（强制真值推next token）
    - 训练ID生成器：为了梯度，在token生成阶段就取token生成的logits，利用这个logits通过推荐器embedding层合成平均token embedding（避免max操作），直接插入推荐器获取损失
  - 基本上ID只需要10位token左右（最高20k个item）
  - 实验结果来看，即使是非zero-shot，也有IDGenRec>P5>tradition
  - 思考：可这和interest journey的操作何其相似（而且这篇文章比较老）
- SIGIR-AP '23, [How to Index Item IDs for Recommendation Foundation Models](https://arxiv.org/pdf/2305.06569)[code](https://github.com/Wenyueh/LLM-RecSys-ID)
  - 本文进行的是序列推荐，定义<>内为OOV(Out Of Vocabulary)单词
  - 一个好的索引，长度适中，同时能一定程度代表先验信息
  - 一个背景信息：谱聚类可能可以理解成降维后聚类，只是这个降维运用到了图信息，构建了相似性矩阵。
  - 实验用的是P5框架。
  - 包括独立索引、标题索引、随机索引、序列索引、协作索引、语义索引和混合索引
    - 随机索引(RID)：为每个item随机分配一个或多个ID
    - 标题索引(TID)：用标题当索引
    - 独立索引(IID)：专门生成OOV token
    - 序列索引(SID)：其实就是沿着交互序列一个个编码，逐用户、逐item地编
      - 基本上可以按照时间来排布各个user交互序列时效果最好，其次是按照用户交互数来排
    - 协同索引(CID)：本质分层聚类（聚类方法使用谱聚类），构建成树状结构
    - 语义索引(SemID)：也是树状结构，但是是基于语义树构建
      - 很多时候类别都不是树形的
  - 最后发现，如果融合之后，CID+IID和SID+IID有一点点效果，其余基本没效果。
- NeurIPS '22, [Transformer Memory as a Differentiable Search Index](https://arxiv.org/pdf/2202.06991)(DSI)(Google)
  - DSI: Differentiable Search Index
    - 能够输入文档，输出标识符，seq2seq
    - 能够自回归返回候选docid
    - 同时训练input2target和target2input，通过前缀指令让模型明白任务流向
    - 如何选择index？
      - 直接索引：直接用前L个token作index
      - 集合索引：避免重复，用python的set操作避免
      - 倒排索引：随机抽取L个token作index
    - 一个尝试，对文档通过分层聚类生成标识符，但是效果未必达到了最佳，在个别任务上和普通方法持平
- NeurIPS '22, [A Neural Corpus Indexer for Document Retrieval](https://arxiv.org/pdf/2206.02743)(NCI)(Microsoft)
  - 相比DSI，在decoder加了个位置编码，保证不同语义的解码效果不同
- arXiv '24, [Preference Distillation for Personalized Generative Recommendation](https://arxiv.org/pdf/2407.05033)(PeaPOD)
  - 目的是生成能够反映用户特点的软提示
  - 首先根据用户交互记录生成用户表征和项目表征
  - 利用矩阵分解获得重要度，与注意力矩阵逐点相乘，得到一个attended query，用这个和prompt和attention vector的key进行相似度计算得到权重向量给p加权
  - 主要是POD的改进，自称比POD又高了0-10%
- SIGIR '23, [Generative Sequential Recommendation with GPTRec](https://arxiv.org/pdf/2306.11114)(GPTRec)
  - 也是一种量化方案
  - 基本上是为了解决序列推荐的
  - 具体做法：每个item用数个token表示，其余基本等同sasrec，效果也勉强与SASRec持平
- arXiv '24, [EasyRec: Simple yet Effective Language Models for Recommendation](https://arxiv.org/pdf/2408.08821)[code](https://github.com/HKUDS/EasyRec)
  - 利用item信息生成item摘要(profile)
  - 利用用户对item的评价和item摘要生成user摘要
  - 把这两个东西过类BERT得到embedding
  - 对比学习进行协同过滤
  - 完

##### 好像不是特别相关
- arXiv '24, [Transparent and Scrutable Recommendations Using Natural Language User Profiles](https://arxiv.org/pdf/2402.05810)
  - 通过用户交互序列生成自然语言化的user profile，添加到prompt中
  - 利用用户打分和用户评语来判断用户对item的喜好，从而计算出用户最感兴趣的的商品排名（感觉不如传统推荐系统，但这个是自然语言化的，用了情感词评价系统）
  - 用LLM总结生成profile，没啥特别的
##### recsys24
- 看到了很多GCL（图对比学习）工作，至少有4篇+
- 由于论文滞后性，LLM+推荐（一般为对话式推荐或者是增强推荐）有点早了，点名表扬CALRec, KAR等
- 联邦学习和持续学习总归是一直在弄的，但是看不懂
- 似乎采样也是个关键点，虽然不太确定

#### PQ相关内容
- 重要survey, [Embedding in Recommender Systems: A Survey](https://arxiv.org/pdf/2310.18608)
- 这些工作的格式很好，用用：
  - [Dual Graph enhanced Embedding Neural Network for CTR Prediction](https://arxiv.org/pdf/2106.00314)
  - [KGAT: Knowledge Graph Attention Network for Recommendation](https://arxiv.org/pdf/1905.07854)
  - [Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System](https://arxiv.org/pdf/2010.15363)
  - [Interactive Path Reasoning on Graph for Conversational Recommendation](https://arxiv.org/pdf/2007.00194)
  - [Deconfounded Recommendation for Alleviating Bias Amplification](https://dl.acm.org/doi/pdf/10.1145/3447548.3467249)
  - [Modeling Extreme Events in Time Series Prediction](https://hexiangnan.github.io/papers/kdd19-timeseries.pdf)
  - [Causal Attention for Interpretable and Generalizable Graph Classification](https://arxiv.org/pdf/2112.15089)

一个灵感：启发自[Matching-oriented Product Quantization For Ad-hoc Retrieval](https://arxiv.org/pdf/2104.07858)，这里展示了更小的重建损失并不能带来更好的推荐性能，与我们思路相同

#### 下面专门统计大模型如何建模序列信息
- 生成兴趣聚类来表示
  - **arXiv 23, [Large Language Models for User Interest Journeys](https://arxiv.org/pdf/2305.15498.pdf)(Google)**（意图理解）
- 输入item序列
  - Rella，分段输入
  - TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation，直接输入并且微调
  - MM '23, [Knowledge Prompt-tuning for Sequential Recommendation](https://arxiv.org/pdf/2308.08459.pdf)(KP4SR)，掩码模型，同时输入了三元组知识图谱信息
  - [A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems](https://arxiv.org/pdf/2308.08434.pdf)(BigRec)
  - [ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models](https://arxiv.org/pdf/2305.06566.pdf)
  - arXiv '23, [Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs](https://arxiv.org/pdf/2307.03393.pdf)，直接把图结构转化成字典输进去了
- 输入单个item
  - arXiv(KDD)'24, [Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph](https://arxiv.org/pdf/2402.13750)（ant）（阿里）（LLM-KERec），只判断互补关系
  - arXiv '23, [A Multi-facet Paradigm to Bridge Large Language Model and Recommendation](https://arxiv.org/pdf/2310.06491)(NUS)(TransRec)，尝试输入ID、title、attribute，分别看效果
  - arXiv '24, [Knowledge adaptation from large language model to recommendation for practical industrial application](https://arxiv.org/pdf/2405.03988)(Kuaishou)，对单个item做编码
  - arXiv '24, [Rethinking Large Language Model Architectures for Sequential Recommendations](https://arxiv.org/pdf/2402.09543)(LITE-LLM4Rec)，单个item编码后后续还有大模型来处理这些编码
  - arXiv '23, [ControlRec: Bridging the Semantic Gap between Language Model and Personalized Recommendation](https://arxiv.org/pdf/2311.16441.pdf)，文本表征和item表征做对比学习
  - KDD '22, [Towards Universal Sequence Representation Learning for Recommender Systems](https://arxiv.org/pdf/2206.05941.pdf)(UniSRec)，白化，对比（item级+seq级）
  - arXiv '23, [ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction](https://arxiv.org/pdf/2310.09234.pdf)
- 既输入单个item也输入序列
  - arXiv '24, [CALRec: Contrastive Alignment of Generative LLMs For Sequential Recommendation](https://arxiv.org/pdf/2405.02429)(google)，分别获得embedding
  - arXiv '23, [Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models](https://arxiv.org/pdf/2306.10933.pdf)（KAR）
  - arXiv '23, [CTRL: Connect Collaborative and Language Model for CTR Prediction](https://arxiv.org/pdf/2306.02841.pdf)
  - WSDM '24, [LLMRec: Large Language Models with Graph Augmentation for Recommendation](https://arxiv.org/pdf/2311.00423.pdf)，大模型只负责采样和item文本增强
  - arXiv '24, [Large Language Model Interaction Simulator for Cold-Start Item Recommendation](https://arxiv.org/pdf/2402.09176.pdf)(LLM-InS)，直接问是否，用来编码
- 输入处理后的IDembedding
  - WWW '24, [Enhancing Sequential Recommendation via LLM-basedSemantic Embedding Learning](https://dl.acm.org/doi/pdf/10.1145/3589335.3648307)(SAID)(浙江大学)(ali)(阿里)(支付宝)
  - arXiv '23, [CoLLM: Integrating Collaborative Embeddings into Large Language Models for Recommendation](https://arxiv.org/pdf/2310.19488.pdf)
  - arXiv '23, [LLaRA: Aligning Large Language Models with Sequential Recommenders](https://arxiv.org/pdf/2312.02445.pdf)

#### 大模型兴趣建模
- **arXiv 23, [Large Language Models for User Interest Journeys](https://arxiv.org/pdf/2305.15498.pdf)(Google)**（意图理解）
  - 过去的推荐系统专注于单次的推荐结果，现在对用户兴趣行程(journey)进行建模（一个完整的工作流，从产生兴趣、到主动大量交互，到产生结果）
  - 对于一个大数据流，使用UMAP(Uniform Manifold Approximation and Projection)进行聚类（降维），这是一种基于流形的算法，可以视作t-SNE的一个改进版。
  - 洞见:
    - 用户倾向于娱乐、学习和社交兴趣。
    - 用户行为是多兴趣混合的
    - 现有用户更多使用搜索框而非推荐栏来找寻兴趣
    - 用户兴趣各异，并且也会被推荐系统所影响
  - 进行连贯的兴趣聚类，删除单个行为，并且用大模型进行命名
  - 首先从文本中生成关键词并且附带上监督模型打的显著性分数，然后基于用户兴趣，把项目分给最近的journey（一种聚类）
  - 主要目的：聚类用户兴趣，提升推荐效果
- Rella（框架）
  - 作为CTR预测时，控制输出token为1，将yes/no的估计分（softmax前）作为预测的CTR
  - 使用大模型的最后一层表征(mean pooling)再PCA降维作为item表征
  - 基于Target item对过去的交互序列进行召回
  - 将recent-k + relevence-top-k 混合输入
- 传统多兴趣建模
  - CIKM'19, MIND（阿里）
    - 利用动态路由，将用户兴趣映射到各个胶囊表示中
  - CIKM'20, DMIN（阿里）
    - 使用multi-head self-attention获得行为表示，然后再次使用之，用多注意力头提取多兴趣
    - 整体结构应该是用DIN做的骨架
  - KDD'20, ComiRec（阿里）
- arXiv(KDD)'24, [Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph](https://arxiv.org/pdf/2402.13750)（ant）（阿里）（LLM-KERec）
  - 现有RS的两大局限：
    - 冷启动效果差
    - 推荐能力差，现有模型更善于推荐替代品而非互补品
  - 不能只把LLM当encoder来用
  - 提取entity，LLM构建互补图；设计互补召回模块；
  - 实体提取：
    - 实体是预定义的实体字典，一般是明确名词，并且每周更新。
    - 现在是利用BERT-CRF模型对每个item生成一个唯一（unique，这里的unique存疑，因为下面又在说这样用entity能够节省运算资源）的实体（名词，比如舒客小苏打牙膏就被认定为牙膏）
  - 互补图构建
    - 分类成了极流行、流行和不流行，只在流行实体内、极流行和不流行之间配对
    - 通过构建prompt的方式（包括输入输出格式、问题描述和举例）来获知两个entity之间有没有互补关系
  - E-E-I图
    - 使用GAT来建模一阶关系，分别建模U-E关系和I-E关系，再attention融合
    - 两条路线建模互补关系，然后注意力建模：
      - I-E-E(item找到互补entity)
      - I-U-I-E(item找到相同user交互过的item对应的entity)
    - 一阶与二阶进行对比学习
  - 最终模型：
    - 一切围绕着这张互补图进行
      - Recall阶段，在basic recall之余，使用图的embedding再召回一部分item
      - 在打分阶段，使用Ranking stage打分
- NeurIPS'22, [Concept Embedding Models: Beyond the Accuracy-Explainability Trade-Off](https://arxiv.org/pdf/2209.09056.pdf)
  - 传统CBM(Concept Bottleneck Model)旨在用concept替代embedding，提升可解释性。
    - 然而，这会带来显然的效果下降，因为这样的concept可能无法完全涵盖item信息，准确性与可解释性不可兼得
    - 并且传统CBM的训练数据难以获得（较差的训练数据和分类结果也会导致性能变差）
  - 具体流程
    - 为每个concept生成两个embedding（基于DNN生成初步embedding，然后用全连接层为每个concept分别得到两个表征）
    - 学一个s函数来从正负embedding中获得概率p值，监督信号是真实01，然后将这个值乘正例，1-p乘负例embedding
    - 预测过程中，通过显式p值，人可以更改中间结果p，从而影响结果
    - 提出CAS方法，将样本聚类，然后给每个x一个聚类标签，然后计算样本真实概念标签与聚类标签之间的条件熵
- NeurIPS'23, [Learning to Receive Help: Intervention-Aware Concept Embedding Models](https://arxiv.org/pdf/2309.16928.pdf)
  - 上一篇的后续工作
  - 提升模型接受训练过程中的concept更改的能力
  - 学习干预策略+正则惩罚沿着干预轨迹预测错误的情况
  - 在预测中，模型与CEM无异（但是输出概率函数）
  - 训练过程中，学习一个策略fai来预测干预中选择哪个概念进行干预
- arXiv '23, [A Multi-facet Paradigm to Bridge Large Language Model and Recommendation](https://arxiv.org/pdf/2310.06491)(NUS)(TransRec)
  - 局限：
    - ID标识对大模型而言很难理解，需要大量微调
    - 语义标识缺乏区分度，同时描述相似的item未必有相似的交互
  - 分别构建ID、title、attribute指令数据集
  - 使用FM索引来生成有效token，在每个指令集内，利用生成对应token的概率计算得分，在指令集之间，利用超参数和相似度计算总得分
  - ID和title最为关键，attribute和FM索引法相对影响较小一些
- NIPS '23, [Recommender Systems with Generative Retrieval](https://arxiv.org/pdf/2305.05065.pdf)(TIGER)(Google)
  - 简略版：
    - 给定一个item的文本描述，使用预训练的文本编码器生成dense的embedding，然后量化生成语义ID，再根据语义ID反推出语义ID对应的embedding，经过平均池化就能得到每个语义ID的embedding了
    - 之后使用这种语义ID（也就是说embedding皆已固定）进行推荐，接下来构造负例，分别是把ID半修改生成的负例、把同batch的其他预测ID作为负例；通过置换矩阵使得多个域能对齐
  - 重看版：
    - 避免矩阵分解范式，直接预测候选id的端到端生成范式，尾部是一个生成式检索模型
    - 使用文本编码器为item生成embedding，然后使用量化获得语义ID，优点有3：
      - 基于语义的ID在相似item上天然具有相似性
      - 避免内在反馈循环(inherent feedback loop)，推荐系统会倾向于忽略长尾节点
      - 减轻存储压力
    - 在生成语义ID之后，直接将语义ID送入seq2seq模型进行训练，例如，i_1=(3,2,4), i_2=(7,4,1), i_3=(2,1,5)，则输入(3,2,4,7,4,1,2,1,5)，来预测接下来三个id
- WWW '23, [Learning Vector-Quantized Item Representation for Transferable Sequential Recommenders](https://arxiv.org/pdf/2210.12316.pdf)(VQ-Rec)(人大)
  - 给定文本信息，利用RQ-VAE技术，将文本编码并量化为语义ID；由于RQ-VAE存在编码坍塌的问题，考虑使用k-means和VQ-VAE进行编码；碰撞则额外加一维进行编码
  - 直接训练一个序列到序列模型，生成预测item的语义ID，实验中使用T5X模型
  - 实验发现生成无效ID的数量不大，而且效果很好（效率应该不高）
  - 重看：
    - VQ-Rec认为item rep.和text rep.过于紧密，问题如下：
      - 过分强调文本相似性，忽略序列性
      - 文本的不同表述可能导致在语义空间的映射不同
    - 目的：预训练一个可转移的序列推荐器
    - 转移中，训练一个转移矩阵，这个转移矩阵基于Birkhoff-von Neumann定理进行优化，用来转移码元嵌入
- arXiv '24, [Knowledge adaptation from large language model to recommendation for practical industrial application](https://arxiv.org/pdf/2405.03988)(Kuaishou)
  - 现有问题：
    - 推荐数据量大，LLM推理速度慢、输入长度有限
    - 灾难性遗忘和性能问题
  - 挑战：
    - 领域适配微调过程中导致原始性能下降
    - 预训练目标不匹配
  - 工作：将知识从LLM适配到推荐
    - 双塔结构，嵌入模块&理解模块
    - item进行句子描述之后，对token的输出进行平均池化得到嵌入（效果好于最后一个item的嵌入）
    - 对比学习：固定ui，同u不同i为正例，不同u的交互为负例
  - 实验结果
    - 相比id嵌入和BERT嵌入，LLM嵌入效果更好
    - 冻结大模型做编码好于微调大模型编码好于冻结大模型生成
    - 发现在H@10和N@10上效果不如HSTU，但是H@50和N@50上更好
    - 单向masked attention超过了自注意力超过了什么都不做
- arXiv '24, [CALRec: Contrastive Alignment of Generative LLMs For Sequential Recommendation](https://arxiv.org/pdf/2405.02429)(google)
  - 两阶段大模型微调方法，双塔模型，基于文本进行推荐
    - 纯文本输入，提示工程设计
    - 混合训练目标，包括自定义next item生成和辅助的对比任务
    - 混合finetune+特定任务finetune
    - BM25商品检索方法
  - 任务看作一个seq2seq生成式任务，类似TALLRec，输入是user交互序列，输出是next_item文本，然后作交叉熵损失
  - LLM对user history的平均池化embedding 对比学习 LLM对target item的平均池化embedding
  - LLM对next item的平均池化embedding 对比学习 LLM对target item的平均池化embedding
  - 推理的时候，优先根据大模型生成分数进行排名，然后对各个位置用BM25找到最近item
  - 训练
    - 使用amazon的14个产品类别，全部用于1阶段微调，然后将其中6个进行类别特定微调
    - 发现amazon存在部分重复记录，可能导致推荐性能不佳
  - 实验结果
    - 发现不需要BM25也可以有较为精确的匹配，实际上超过99.9%的输出符合标准，标题有95-99.8%可以直接匹配到
    - 实验发现微调带来了巨大收益（基于PaLM-2），其次两个阶段的微调重要程度基本相同
- KDD '22, [Towards Universal Sequence Representation Learning for Recommender Systems](https://arxiv.org/pdf/2206.05941.pdf)(UniSRec)
  - 利用text进行跨域信息迁移
  - 文本编码就用BERT，但是发现BERT的编码不适合直接用于推荐，而且多个领域的BERT编码语义差距很大，因此可以使用whiten方法，使用线性变换进行白化
  - 多域语义通过MoE进行融合，然后过Attention
  - 采样的时候尝试每一项和正下一项（负样用batch内的其他item）做对比学习；域间序列信息随机drop掉序列中的item/随机drop掉词进行对比学习（负例用batch内的其他序列）
- KDD '23, [Text Is All You Need: Learning Language Representations for Sequential Recommendation](https://arxiv.org/pdf/2305.13731.pdf)(RecFormer)
    - 在序列推荐中，对项目进行“句子”化
    - motivation：id限制了冷启动能力
    - 将每个item对应到一套键值对字典，分别表示color、brand等，这样每一个item都能转化成一个句子，历史序列就是n个句子
    - 为每个“句子”进行四种编码，正常embedding、位置embedding、键值对level embedding、“句子”位置embedding
    - 这样，user embedding就由若干个“句子”的embedding组成，而item embedding就由单个“句子”的embedding组成
    - 训练过程模仿BERT，将一部分内容掩码重建；使用正例/负例的对比进行训练
    - 训练一阶段更新特征矩阵I和其余参数，第二阶段冻住I继续训练其余参数
    - 提升相当明显，但是预训练的数据并非越多越好，而是在4k个左右达到最好
- WWW '24, [Enhancing Sequential Recommendation via LLM-basedSemantic Embedding Learning](https://dl.acm.org/doi/pdf/10.1145/3589335.3648307)(SAID)(浙江大学)(ali)(阿里)(支付宝)
  - 现有问题：
    - 大模型提取的文本表征相对粒度较粗，无法捕获细粒度
    - 大模型受到长度限制
  - 模型比较简单
    - stage1用mlp来将item id投影到LLM中
    - stage2用这个mlp来作为embedding输入seq模型中
  - 结果可观
    - 相比提取llm最后一层，这种方式训练的效果更好
    - 可以将这种训练范式看作一种embedding初始化，从这个视角看的话，可以发现其性能超过了传统的初始化方法。同时，后续继续进行训练能够将效果进一步提升。
- WWW '24, [Aligned Side Information Fusion Method for SequentialRecommendation](https://dl.acm.org/doi/pdf/10.1145/3589335.3648308)(ant)(蚂蚁)
  - 探索一种id信息和辅助信息混合的方式，总结来看方法较为复杂
- WWW '24, [Context-based Fast Recommendation Strategy for Long User Behavior Sequence in Meituan Waimai](https://arxiv.org/pdf/2403.12566)(CoFARS)(meituan)(美团)
  - 识别出与目标上下文具有相似用户偏好的上下文，从而找到响应兴趣点，解决超长序列问题
  - 
- arXiv '24, [Rethinking Large Language Model Architectures for Sequential Recommendations](https://arxiv.org/pdf/2402.09543)(LITE-LLM4Rec)
  - 问题
    - LLM4Rec计算开销大
    - 束搜索解码非常耗时
    - token化输入引入了过多的计算
  - 方法
    - 上下文感知嵌入：item信息输入大模型，表征做平均池化
    - 序列表示获取：大模型继续编码之前获得的所有item表征，随后使用平均池化获得user表征
    - user表征过MLP得到对物品集的输出得分（提高速度，避免大模型的冗余计算）
- SIGIR '24, [UniSAR: Modeling User Transition Behaviors between Search and Recommendation](https://arxiv.org/pdf/2404.09520)(UniSAR)(思考下更多可能)(Kuaishou)
  - 搜推融合：提取 对齐 融合
  - 用户会出现搜和推的转换，因此会出现留存/转换，共4种操作
  - 具体方法：
    - 嵌入模块
      - 采用三个嵌入矩阵，user，item和查询query
      - 查询嵌入直接将查询词的嵌入平均池化，之后使用id embedding，如果是搜索嵌入则直接加上查询嵌入
      - e_q（搜索中的item嵌入）和e_i（推荐中的item交互）做对比学习
    - 转换模块
      - 取出s子序列和r子序列做出嵌入，加入位置编码，于子历史序列内部进行多头自注意力编码
      - 在完整序列中加入掩码，让注意力交互只在r-s之间进行，不在rr和ss内进行
    - 对齐模块
      - 将s2s/r2r和r2s分别对比学习，loss相加
    - 融合模块
      - 首先由s2s和r2r做msa，然后将r2s做q，msa结果做kv，作为item最终表示
      - 再通过与目标项的注意力计算来得到搜和推的历史聚合表示
      - 历史交互拼成序列交给MMOE进行预测
  - 实验结果
    - 从实验结果看，似乎r2s和s2r的作用并不算太大？
- arXiv '24, [Learnable Tokenizer for LLM-based Generative Recommendation](https://arxiv.org/pdf/2405.07314)(LETTER)(NUS)(冯福利)
  - 哈哈，和我的想法基本一样
  - 使用对比学习进行CF-大模型表征拉近
  - 类似tiger的生成式推荐方法
- life-long learning
  - 灾难性遗忘/可塑性与稳定性
  - 必须能够从新的更新中获益，并且避免灾难性遗忘
  - 同时适应：
    - 场景不一致
    - 任务不同
    - 不修改backbone
    - 非平稳演化（分布不一致）
  - 解决方案：
    - 基于replay
      - 利用一部分过往数据(GEM)
      - 利用meta-learning(MER)（学到具有泛化能力的元特征）（保证在j域经过更新后，在i域训练，保持泛化到j域的能力
    - 基于正则化
      - data-focused：构建输入数据或采样，将这部分数据的旧结果进行知识蒸馏
      - Prior-focused：将参数的估计分布作为先验，惩罚关键修改
        - EWC：固定A域修改量大的参数，B域训练时尽量只修改A域修改量小的参数
    - 基于模型结构
- arXiv '24, [The Elephant in the Room: Rethinking the Usage of Pre-trained Language Model in Sequential Recommendation](https://arxiv.org/pdf/2404.08796)
  - 研究PLM在SR中的适配性，发现，可能PLM并不适合SR任务，提出了一种基于PLM的初始化方法
  - 现有问题
    - 只基于文本的工作，通常情况下在交互足够的情况下比不过正常序列模型
    - 当引入序列信息时，大多数未考虑适配问题
    - recformer
      - 首先预训练一个基于文本的推荐模型（MLM+IIC）
      - 然后预生成item enmbedding，利用这个微调整个模型M+item embedding I，这个过程中会诞生一个最好的M-I组合
      - 现在已经更新了M和I了，然后现在完全固定I，只更新M
    - 发现不同层的attention的关注点不同，分为0-3/4-7/8-11，4-7关注每个item的第一个token，8-11类似SASRec，关注近期的token和关键token，也就是说，其实recformer更加接近SASRec，而非LongFormer。也就是说，RecFormer非常冗余。进一步实验发现，只调一部分的LongFormer，效果更好Table1
    - 问题：
      - 需要PLM这么强的能力吗？简单模型能替代吗？
      - 如何在SR中利用PLM？
      - PLM集合到SR中应该是什么样的？
    - 结论：
      - PLM能力没有被充分激发
      - 基于行为微调之后的PLM编码效果很好，但是普通的PLM编码没什么用。
      - 基于行为微调之后的PLM编码在下游任务上继续训练效果很好。
      - 当SR的架构和训练目标和PLM相似的时候效果更好（从BERT4Rec>SASRec中得出，个人存疑）
- arXiv'24, [Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation](https://arxiv.org/pdf/2311.09049)(人大)(LC-Rec)
  - 现有方法：
    - 将行为化为文本交给大模型，但是信息有限、依赖候选集
    - 设计特殊的项目索引，但是现在效果不太好
  - 现有工作的局限性：
    - 序列推荐方法，没有语义
    - LLM方法：
      - 提示并不能完全解决对齐和生成质量等问题
      - 自然语言序列微调：难以生成候选集外物品
      - ID索引输入：大模型理解ID困难
  - 理想的情况：生成有意义、唯一、可扩展的语义ID
  - 本模型旨在：对齐自然语言和序列数据
  - VQ方法，基于RQ-VAE生成语义编码，利用SinkhornKnopp算法（利用双随机矩阵）优化编码器
    - 训练过程，要求通过描述生成令牌，通过令牌生成描述
    - 对齐过程：令牌序列到标题、令牌序列到描述、标题序列到令牌
    - 意图理解：意图到令牌、意图+令牌序列到令牌、令牌序列到意图
  - 训练，正常训练，指令-结果对loss，
- arXiv'24, [Vector Quantization for Recommender Systems: A Review and Outlook](https://arxiv.org/pdf/2405.03110)
  - VQ在推荐中的作用：
    - 效率方面：空间压缩、模型加速、提升检索速度
    - 质量方面：特征增强、模态对齐、离散token化
    - 生成式推荐、集成大模型
  - VQ面临的问题:
    - 码本利用度不足
    - 对齐问题
    - 码本质量难以评估，依赖下游任务
- arXiv'24, [Multi-Behavior Generative Recommendation](https://arxiv.org/pdf/2405.16871v1)([Code](https://github.com/anananan116/MBGen))
  - 包含了VQ方法的多行为生成式模型
  - VQ方法：改进的RQ-VAE，不使用残差，而是先KMeans生成第一层code，然后对每个一层code的残差都单独做KMeans，从而生成第二层Code，最后消除相同项生成第三层Code.（解决Code分布不平均问题）
  - 多行为方法：使用类似HSTU的方法，把behavior作为token输入


#### 结构化embedding
- [Galaxy Network Embedding: A Hierarchical Community Structure Preserving Approach](https://www.ijcai.org/proceedings/2018/0287.pdf)
- [Hierarchical Taxonomy Aware Network Embedding](https://pengcui.thumedialab.com/papers/NE-Hierarchical.pdf)
- [Contrastive Multi-view Hyperbolic Hierarchical Clustering](https://arxiv.org/pdf/2205.02618.pdf)

#### 大模型alignment
- 超对齐(Superalignment)概念：与把人类价值观硬编码进人工智能系统不同，让AI自身内省地认知伦理概念
- [Aligning Large Language Models with Human: A Survey](https://arxiv.org/pdf/2307.12966.pdf)
    - 包含三大方面：数据收集、训练方法、模型评估
        - 数据收集：如何有效收集大规模高质量的LLM对齐训练数据？利用NLP baseline，人工标注或LLM标注
            - 人工指令：由人构建
            - 自指令：CoT、角色扮演、师生模型、多轮对话，考虑指令类型和数量
        - 训练方法：参数有效性的方法/奖励函数法
            - 对齐训练：RLHF、RAFT、基于评分的更新和基于内容的对齐，以及基于参数的对齐
        - 模型评估：以人为中心的评估/自动评估基准
            - 数据集：通识数据集、推理数据集、coding数据集、对比/技能数据集
            - 评估范式：人工评估/大模型辅助评估/大模型评判好坏
    - 未来方向：细粒度数据处理、非英语语言、大模型对齐训练、人类评估影响
- [AI Alignment: A Comprehensive Survey](https://arxiv.org/pdf/2310.19852.pdf)
    - 前向对齐：通过对齐训练使AI系统对齐
        - 从反馈中学习
            - RLHF、
        - 在分布偏移下学习
            - 如何缓解训练数据的有偏性：算法&数据操作
    - 后向对齐：获取有关系统对齐的证据并管理
        - 建立监管架构来保证训练系统对齐
            - 安全评估、可解释
        - 确保AI系统安全开发和部署的规则的制订和实施
            - 法规、审计、政策等
    - 四个基本原则：鲁棒性、可解释、可控、伦理性
- Recsys '23, [Leveraging Large Language Models for Sequential Recommendation](https://dl.acm.org/doi/pdf/10.1145/3604915.3610639)(LLM2BERT4Rec)
    - 基于大模型的编码，尝试了几种策略
    - 获得嵌入部分，通过将序列产品的嵌入通过多种获取方式组合进session来提升效果
    - 指令微调部分，将序列作为输入，最后一个item名称作为输出进行微调，提升大模型的序列表征能力
    - 使用主成分分析来将LLM嵌入维度对齐到BERT4Rec嵌入维度
- arXiv '23, [ControlRec: Bridging the Semantic Gap between Language Model and Personalized Recommendation](https://arxiv.org/pdf/2311.16441.pdf)
    - 两个任务：异构特征匹配和指令对比学习
    - 异构特征匹配分为：根据描述和item进行交叉熵loss对齐；根据对target item和历史序列的embedding进行交叉熵loss对齐
    - 指令对比学习是由GPT为模型生成更多的扩展prompt，然后基于这些prompt生成预测的分数结果（由大模型生成embedding然后再平均池化，然后再和目标embedding点积），和原本的分数（0或1）进行对比得到对比损失
    - 最终的loss由三部分组成：推荐损失、对齐损失、对比损失。
- EMNLP '20, [On the Sentence Embeddings from Pre-trained Language Models](https://arxiv.org/pdf/2011.05864.pdf)(BERT-flow)
  - 将BERT生成的编码从非光滑各向异性的转化为光滑的各向同性的高斯分布。
  - 好难懂...
- [Adapting Large Language Models by Integrating Collaborative Semantics for Recommendation]

#### 大模型与推荐系统
- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
    - 以下内容应该基本来自于该综述
- Large Language Models are Zero-Shot Rankers for Recommender Systems
    - 评测了LLM在推荐系统中的零样本排序能力
    - LLM能根据历史交互实现个性化排序，但是很难感知到用户历史交互的序列关系
    - 零样本能力很好，但是存在position bias和popularity bias
- Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System
    - 构建对话式推荐系统，在这里，LLM能够对用户推荐并且提供个性化解释
- Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models
    - 改善对话式推荐的评测方式，使其更加关注于对话推荐系统的交互能力
    - 使用LLM用户模拟器来测试LLM的对话推荐能力
- Zero-Shot Next-Item Recommendation using Large Pretrained Language Models
    - 评测零样本设定下LLM在下一个物品预测任务下的能力。
    - 使用外部模块生成候选物品，然后分别提示LLM：提取用户偏好、选择代表性历史交互物品、推荐并排序前10
    - 零样本能力极好
- Is ChatGPT a Good Recommender? A Preliminary Study
    - 在评分预测、序列推荐、直接推荐、解释生成和评论摘要五个任务下测试了chatgpt性能
    - 发现评分预测、解释生成和评论摘要任务表现较好
    - 从人类角度，LLM生成的解释和摘要更清晰符合逻辑（但是传统评测指标下不好）
- Uncovering ChatGPT’s Capabilities in Recommender Systems
    - 分析chatgpt在point-wise, pair-wise, list-wise的排序能力
    - list-wise具有最高性价比。
    - 能够缓解冷启动问题、提升可解释效果
- Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction
    - 专门评测LLM在评分预测任务上的表现
    - 冷启动下模型参数增加效果更好
    - 零样本设定下，LLM效果远差于完整数据上的传统模型
    - LLM的data efficiency更好，小数据可以取得优于传统模型的结果
- Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation
    - LLM存在一定的社会偏见
    - 提出公平性benchmark，发现LLM可能产生不公平的推荐
- Generative Recommendation: Towards Next-generation Recommender Paradigm
    - 传统方法是从物品集中检索合适的物品，但是已有物品集不一定符合，用户反馈（如点击）很低效
    - 提出生成式推荐范式，基于用户指令和传统反馈，依据AI生成方法重定制已有物品
- GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation
    - 传统ID判别式方法导致无法利用物品内容信息和NLP模型的语言建模能力，无法解释用户兴趣，无法适配商品的增加
    - 基于历史交互物品和对应标题，用gpt2生成假设的搜索查询，引入搜索引擎来检索
- A First Look at LLM-Powered Generative News Recommendation
    - 传统新闻推荐面临冷启动、用户画像建模、新闻内容理解问题
    - 利用可获得数据来构建提示，从而激发LLM基于通用知识产生相关信息
- Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach
    - 传统ID推荐难泛化、用户的参与比较被动
    - 用户历史+评论构成指令，从而微调大模型以推荐
- TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation
    - LLM的训练任务和推荐任务的不一致导致了次优结果
    - 指令微调阶段之后，进行推荐微调，将推荐数据化为指令微调格式，利用历史交互判断是否喜欢目标商品
- arXiv '23, [Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models](https://arxiv.org/pdf/2306.10933.pdf)（KAR）
    - 用户行为和个人信息属于开放世界特征，需要被利用起来
    - 利用LLM，将用户信息和商品信息进行扩充，根据用户历史序列推断用户偏好（文本化），根据商品信息扩增商品表述（本次使用了movielens和Amazon—Books，便于提升效果）（把大模型当作知识库来用），然后利用BERT给扩充出的特定token进行编码，从而提升效果（以及，使用专家模型分别处理u，i，ui，不过这并不是什么很难的事罢了）
    - 这样，不但可以将大模型作为知识库增强用户和商品表征，还可以作为一个模型无关、预处理的操作，提升上线效率。
    - 然而，从ablation study中可以看到一个问题，使用item增强带来的提升是有限的，更多更显著的提升来源于对user向量的扩张。
- arXiv '23, [CTRL: Connect Collaborative and Language Model for CTR Prediction](https://arxiv.org/pdf/2306.02841.pdf)
    - 现有的基于语义信号的推荐存在：协同信号建模不足、在线推理复杂度高的问题。
    - 两阶段模型，第一阶段用对比学习跨模态知识对齐，第二阶段用监督信号对下游任务微调
- arXiv '23, [ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction](https://arxiv.org/pdf/2310.09234.pdf)
    - PLM直接进行CTR推理有两个问题：正确率低、速度慢
    - 使用id model做soft prompt
    - 利用id model和PLM结果结合一下输出
- MM '23, [Knowledge Prompt-tuning for Sequential Recommendation](https://arxiv.org/pdf/2308.08459.pdf)(KP4SR)
    - 对于序列信息，将待填入内容进行掩码，然后直接转化为自然语言文本模板（现在看来较为常用的方法，可能在论文发出的时候仍然较为新颖）
    - 基于知识图谱将二跳邻居用嵌套三元组的形式输入大模型，作为一种知识增强手段。值得注意的是，由于大模型内部参数是可改变的，在训练阶段，确保大模型的transformer只与该节点二跳邻居以内的节点交互
    - 本实验基于mask方法，使用了T5模型作为基座，该pipeline不确定能否用于LLM
- [TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation](https://arxiv.org/pdf/2305.00447.pdf)
    - 直接使用大模型预测是否喜欢下一个物品效果非常差
    - 主要focus在LLM和RS的对齐，因此使用instruction来进行格式化输入输出
    - 第一步，利用固有指令微调提升泛化性；第二步，使用特化的指令，把rate信息转化为喜欢和不喜欢，喜欢的是...，不喜欢的是...，接下来.喜不喜欢，这里的item中都包含了属性信息。
- [A Bi-Step Grounding Paradigm for Large Language Models in Recommendation Systems](https://arxiv.org/pdf/2308.08434.pdf)(BigRec)
    - 在这里，试图为整体所有的项目进行排名，因此必须解决：高效、稳定（避免大模型的错误输出等问题）和流行度偏差问题
    - 第一步将LLM的语义空间与推荐语义空间对齐，这样能生成推荐格式的内容，但是难免有虚构的内容；然后进一步将推荐语义空间与实际item空间对齐，达到推荐目的。
    - 发现few-shot和跨域效果很好，然而代价是，增大数据量的提升有限
- [ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models](https://arxiv.org/pdf/2305.06566.pdf)
    - 直接使用闭源LLM作为推荐工具，效果并不能比得上现代的推荐系统
    - 可能最重要的地方是这个框架？利用已有的属性和交互记录，在闭源大模型中对数据进行增强（单轮）/更新（多轮），然后再利用较好的数据去微调开源大模型，从而提升效果。
- arXiv '23, [CoLLM: Integrating Collaborative Embeddings into Large Language Models for Recommendation](https://arxiv.org/pdf/2310.19488.pdf)
    - 跳过大模型的第一层embedding，将对应user和item的ID部分的embedding换成传统模型训练出的embedding。
    
- WSDM '24, [LLMRec: Large Language Models with Graph Augmentation for Recommendation](https://arxiv.org/pdf/2311.00423.pdf)
    - 解决side information的几个问题：信息噪声、信息异构和信息缺失。
    - 首先用普通推荐器选出candidate，然后利用大模型对交互进行采样，从而增强交互边际，进而用于BPR训练
    - 基础方法，利用prompt让大模型生成增强文本，然后再使用编码模型将文本编为embedding
    - 损失函数中将损失排序，只取损失较小的前N个进行损失计算
    - 利用MAE进行特征重构，避免特征过敏感性
- arXiv '23, [Representation Learning with Large Language Models for Recommendation](https://arxiv.org/pdf/2310.15950.pdf)
    - [代码](https://github.com/HKUDS/RLMRec)
    - 利用大模型文本增强后，利用文本编码模型生成语义embedding
    - 通过对比学习/掩码重建的方法进行对齐
- arXiv '23, [One Embedder, Any Task: Instruction-Finetuned Text Embeddings](https://arxiv.org/pdf/2212.09741.pdf)
    - 一种在多任务上训练的文本编码器，可以快速适应多种下游任务
- Toward a Better Understanding of Loss Functions for Collaborative Filtering
- LlamaRec: Two-Stage Recommendation using Large Language Models for  Ranking
- exploring the upper limits of text-based cf using llm
- SIGIR'23, [Where to Go Next for Recommender Systems? ID- vs. Modality-based Recommender Models Revisited](https://arxiv.org/abs/2303.13835)(MoRec)(Fajie Yuan)
  - 用大模型替代ID embedding
- arXiv'23, [Multi-Modality is All You Need for Transferable Recommender Systems](https://arxiv.org/pdf/2312.09602.pdf)(PMMRec)(Fajie Yuan)
- arXiv '23, [LLaRA: Aligning Large Language Models with Sequential Recommenders](https://arxiv.org/pdf/2312.02445.pdf)
    - 何向南老师组的另一篇工作
    - 类似于CoLLM，但是本工作没有和CoLLM进行对比
    - 使用提前训练好的推荐模型对id信息进行编码
- [E4SRec: An Elegant Effective Efficient Extensible Solution of Large Language Models for Sequential Recommendation](https://arxiv.org/pdf/2312.02443.pdf)
    - 预训练序列推荐模型，从而生成ID嵌入
    - 利用权重映射矩阵将大模型的嵌入映射到预测结果
    - 具体代码还没看，感觉很像BIGRec
- Recsys '23, [Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM](https://arxiv.org/pdf/2308.03333.pdf)
  - 对于用户的异构行为数据，转换成自然语言之后，使用ChatGPT进行信息融合，生成融合文本
  - 融合文本和指令相结合后构成prompt，输出是用户对订单的标签，基于ChatGLM-6B微调。
  - 使用了餐饮数据集，发现冷启动上有提升，普通用户上没有，可能是由于大模型对餐饮业不了解所致。
- arXiv '23, [Leveraging Large Language Models in Conversational Recommender Systems](https://arxiv.org/pdf/2305.07961.pdf)(RecLLM)(Google)
  - 对话式推荐
- arXiv '23, [prompt tuning llm on personalized aspect extraction for recommendation](https://arxiv.org/pdf/2306.01475.pdf)(Google)
- arXiv '24, [Large Language Models as Data Augmenters for Cold-Start Item Recommendation](https://arxiv.org/pdf/2402.11724.pdf)(Google, DeepMind)
  - 直接使用PaLM，利用成对问题进行提问，发现直接询问是否喜欢的效果较差，而成对提问效果较好。
- arXiv '24, [SPAR: Personalized Content-Based Recommendation via Long Engagement Attention](https://arxiv.org/pdf/2402.10555.pdf)
  - 基于会话基于内容的推荐，解决长序列问题
  - 将序列切割成子序列，然后分别进行嵌入，从而解决用户序列超过PLM输入限制的问题
  - 使用稀疏attention进行信息传递
- arXiv '24, [LLM-based Federated Recommendation](https://arxiv.org/pdf/2402.09959.pdf)
  - 使用联邦学习进行学习，从而避免隐私泄露
- arXiv '24, [Rec-GPT4V: Multimodal Recommendation with Large Vision-Language Models](https://arxiv.org/pdf/2402.08670.pdf)
  - 利用视觉语言模型进行多模态推荐
  - 给定list进行排名
- arXiv '24, [LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations](https://arxiv.org/pdf/2402.09617.pdf)
  - 图结合embedding模型
  - **有意思，还待细看**
- arXiv '24, [Large Language Model with Graph Convolution for Recommendation](https://arxiv.org/pdf/2402.08859.pdf)(GaCLLM)
  - 又一篇平平无奇用大模型进行embedding的文章，后续接了GCN
- 未发表，SIGIR审稿, [Towards LLM-RecSys Alignment based on Textual ID Learning]()
  - 作为常规大模型推荐器的前缀工具，发挥类似于LLaRa的作用
  - 使用生成模型生成特殊的文本id，具体而言是特殊的短文本（且唯一）
  - 生成方式为多束搜索（diverse beam search），使用前缀树(prefix tree)技术存储特殊ID
- arXiv '23, [UFIN: Universal Feature Interaction Network for Multi-Domain Click-Through Rate Prediction](https://arxiv.org/pdf/2311.15493.pdf)(人大，华为)[代码](https://github.com/RUCAIBox/UFIN)
  - 利用大模型对文本数据进行跨域CTR迁移，使用MoE进行自适应多域协作
  - 利用LLM作为编码器从文本获得embedding（采用具体prompt）
  - 利用MoE融合多个domain的表征
  - 最终表征加和常规ID embedding
- arXiv '24, [Large Language Model Interaction Simulator for Cold-Start Item Recommendation](https://arxiv.org/pdf/2402.09176.pdf)(LLM-InS)
  - 针对冷启动项目进行大模型嵌入
  - **具体还待细看**
- arXiv '24, [Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations](https://arxiv.org/pdf/2402.17152.pdf)(HSTU)(Meta)
  - 基于生成式任务进行推荐
  - **非常重要**
- arXiv '24, [Knowledge adaptation from large language model to recommendation for practical industrial application](https://arxiv.org/pdf/2405.03988)(Kuaishou)(LEARN)
  - 现有问题：
    - 推荐数据量大，LLM推理速度慢、输入长度有限
    - 灾难性遗忘和性能问题
  - 挑战：
    - 领域适配微调过程中导致原始性能下降
    - 预训练目标不匹配
  - 工作：将知识从LLM适配到推荐
    - 双塔结构，嵌入模块&理解模块
    - item进行句子描述之后，对token的输出进行平均池化得到嵌入（效果好于最后一个item的嵌入）
    - 对比学习：固定ui，同u不同i为正例，不同u的交互为负例
  - 实验结果
    - 相比id嵌入和BERT嵌入，LLM嵌入效果更好
    - 冻结大模型做编码好于微调大模型编码好于冻结大模型生成
    - 发现在H@10和N@10上效果不如HSTU，但是H@50和N@50上更好
    - 单向masked attention超过了自注意力超过了什么都不做


#### 大模型结合图结构信息结合
- [老师找的的开源代码](https://github.com/XiaoxinHe/Awesome-Graph-LLM)

- KDD '23, [Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help Multiple Graph Applications](https://arxiv.org/pdf/2306.02592.pdf)
    - 需要一个能够利用大规模异质图语料库的模型
    - 预训练阶段将图转化为文本，然后使用BERT预训练，预训练任务为节点预测和边预测
    - 微调阶段在图上进行图感知的微调
    - GaLM是先将文本编码，再附加到图拓扑上作为图任务解码器的输入，连接预测自监督任务；另一种是用图调LMs，用LMs预热GNN，最后同时训练
- arXiv '23, [Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs](https://arxiv.org/pdf/2307.03393.pdf)
    - 探究了LLM作为辅助器和预测器的不同效果，将图结构进行输入的时候使用了一种字典的形式进行输入
    - 作为辅助器：使用了两种增强文本属性的策略，发现使用深度句子嵌入模型生成节点嵌入有效，增强+整合也证明有效
        - 级联结构；迭代结构；文本增强
    - 作为预测器，展现出一定有效性，但是这次试验存在数据泄露问题，而且有可能错误预测没被发现
- arXiv '23, [Explanations as Features: LLM-Based Features for Text-Attributed Graphs](https://arxiv.org/pdf/2305.19523.pdf)
    - LLM为文本生成总结文本，文本+总结文本再送入LM微调

- KDD '23, [All in One: Multi-task Prompting for Graph Neural Networks](https://arxiv.org/pdf/2307.01504.pdf)
    - 要学习一种可以插入原始图的提示图，通过提示图缩小图预训练与下游任务之间的差距，缓解将先前知识转移到不同领域的困难
    - NLP和图的提示具有相似之处，提示标记、标记结构、插入模式
    - 在这里，提示图也模仿图的结构，有节点和边，节点之间有硬参数、可学参数和恒为0三种连接策略
    - 对于所有任务（节点层面，边层面，图层面）都将它们转化为子图问题（从节点/边扩张成子图）
    - 损失函数为使用提示图$\theta$，预训练模型$\pi$和下游任务$\phi$的总任务损失，联合优化$\theta,\phi$
    - 一种很新的图提示与任务重构方法，用来供预训练图模型获取提示

- GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks

- arXiv '23, [SGL-PT: A Strong Graph Learner with Graph Prompt Tuning]
    - 生成方法具有更好的鲁棒性，可以通过学习局部（数据内）关系来确定节点的特征，但缺乏区别表示；对比方法侧重于通过实例识别学习全局（数据间）表示，但可能会丢失单个图的详细信息。通过非对称设计和动态队列方法，有效地将这两种自监督方法结合起来，得到了一个强大通用的自监督图学习器。
    - 本文设计了一种新的提示函数，将一个掩码超级节点引入到单个图中，并将下游图的分类重新定义为掩码节点重构。通过引入监督图原型对比学习来建立重构特征与语义标签之间的映射，实现了无语言器的类映射。

- When to Pre-Train Graph Neural Networks? An Answer from Data Generation Perspective!

- KDD '22, [GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks]
    - 图上的预训练任务

- arXiv '23, [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/pdf/2305.10601.pdf)

- arXiv '23, [Can Language Models Solve Graph Problems in Natural Language?](https://arxiv.org/abs/2305.10037)（有[代码](https://github.com/Arthur-Heng/NLGraph)）
    - 直接用自然语言把图任务说给LLM听，让LLM作任务
    - 由于数据集过于粗暴，如，{"0": {"question": "Determine if there is a path between two nodes in the graph. Note that (i,j) means that node i and node j are connected with an undirected edge.\nGraph: (0,4) (1,4) (2,4)\nQ: Is there a path between node 0 and node 2?\nA:", "answer": "The answer is yes.", "difficulty": "easy"}}
- arXiv '23, [GPT4Graph: Can Large Language Models Understand Graph Structured Data? An Empirical Evaluation and Benchmarking](https://arxiv.org/abs/2305.15066)
    - 探究LLM的各种图任务能力，包括Graph Size Detection, Degree Detection, Edge Detection, Attribute Retrieval, Diameter Computing, Clustering Coefficient Computing, Knowledge Graph Question Answering, Graph Query Language Generation, Node Classification, and Graph Classification.
- arXiv '23, [Can LLMs Effectively Leverage Graph Structural Information: When and Why](https://arxiv.org/pdf/2309.16595.pdf)
    - 探究大模型能否理解结构化数据，并且探究大模型为何可以理解结构化数据
    - 关于结构化数据，将引文网络转化为自然语言送入大模型中，从而让大模型进行处理；并且结果表明，即使文本信息欠缺，结构信息也能发挥作用。
    - 通过实验证明了模型在较浅的思维深度上的有效性。

- AAAI '23, [Exploring Large Language Model for Graph Data Understanding in Online Job Recommendations](https://arxiv.org/pdf/2307.05722.pdf)
    - 建立随机游走元网络，通过一个代价较低的网络学习一个游走策略，在applicant-job匹配图上进行游走，获取prompt推送给大模型
    - 大模型基于prompt进行推荐，使用yes/no模式来为求职者找到最适合他的目标。
- arXiv '23, [BertNet: Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models](https://arxiv.org/pdf/2206.14268.pdf)
    - 解决知识图谱的实体抽取问题
    - 利用人标注的优质实体对和其对应的关系文本（其中有专门填写对应实体对的对应位置），先将它们输入LM来生成更多的相似关系文本
    - 然后利用优质实体对和生成的关系文本，为每个关系文本进行打分，从而获得每个关系文本的权重，在最后用来加权
    - 对于丰富的文本库，将生成的关系文本和文本库输入语言模型，生成可填充的实体对，从而获得新的实体对
    - 再根据实体对和关系文本的嵌合度*关系文本自身权重，生成每个实体对的分数，实现实体抽取
- NIPS '23(?), [WalkLM: A Uniform Language Model Fine-tuning Framework for Attributed Graph Embedding](http://www.cs.emory.edu/~jyang71/files/walklm.pdf)



- exploring the upper limits of text-based cf using llm

#### 多模态大模型——主要基于转换器来连接图形编码器和文本编码器
- arXiv '23, [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models](https://arxiv.org/pdf/2303.04671.pdf)
    - 提出一个prompt manager，负责显式告知chatgpt每个VFM的能力并指定输入输出格式；将视觉数据转化为语言格式；处理不同VFM的历史、优先级和冲突
- arXiv '23, [Language Is Not All You Need: Aligning Perception with Language Models](https://arxiv.org/pdf/2302.14045.pdf)
    - 输入多模态数据，除了文本，其他模态先进行嵌入再输入，使用标签说明每输入的一部分分别是什么
    - 进行纯语言指令微调
- arXiv '21, [Multimodal Few-Shot Learning with Frozen Language Models](https://arxiv.org/abs/2106.13884)
    - 多模态领域使用prompt解决少样本问题
    - 加入一个vision encoder将图编码，然后和embedding好的文本送入LM中
- arXiv '23, [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/pdf/2301.12597.pdf)
    - 通过已经预训练好的视觉和语言单模态模型进行训练
    - 先训一个Q-Former学习提取图像中的文本信息，使用图像-文本对比学习、图像的文本生成、图像文本匹配
    - 将Q-Former的输出交给LLM，使其get图像信息
- arXiv '23, [Grounding Language Models to Images for Multimodal Generation](https://arxiv.org/pdf/2301.13823.pdf)
    - 使用多任务方式训练一个预训练过的文本模型和一个预训练过的图像模型
    - 学习一个翻译参数，充当视觉信息和语言信息中间的桥梁，进行图像到文字的转换，和字幕到图像的检索
- arXiv '23, [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention](https://arxiv.org/pdf/2303.16199.pdf)
    - 采用一组可学习的适应性提示，在深层transformer中将一组可学习的自适应提示作为前缀加到指令token，因此也能加入图片
    - 优点是高效，而且允许多种模态输入
- arXiv '23, [Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning](https://arxiv.org/pdf/2302.14794.pdf)
    - 定义一个元映射网络，将多模态任务分解为一组多模态小样本任务
    - 元网络根据视觉特征学一个前缀捕获有意义的信息

#### 跨域序列推荐
- WWW '23, [Learning Vector-Qantized Item Representation for Transferable Sequential Recommender](https://dl.acm.org/doi/pdf/10.1145/3543507.3583434)
- SIGIR '19, [π-Net: A Parallel Information-sharing Network for Shared-account Cross-domain Sequential Recommendations](https://dl.acm.org/doi/pdf/10.1145/3331184.3331200)
    - *研究Shared-account Cross-domain Sequential recommendation(SCSR)问题，解决多人共用一个账号的跨域推荐问题*，但是要求用户行为时间信息是可对齐的
    - 首先对序列进行编码，然后学习用户特定表示来识别不同用户模式，然后用门控制信息流动到另一个域，最后解码推荐
    - 其中，不同用户模式的识别很类似于多兴趣建模；流动则依靠时间戳，直接建模两个域的ID(?)
- arxiv '21, [DA-GCN: A domain-aware attentive graph convolution network for shared-account cross-domain sequential recommendation](https://arxiv.org/pdf/2105.03300.pdf)
    - *研究SCSR问题，目前方法依赖于顺序关系建模，对域间实体关系捕获能力弱*
    - 直接建立跨域序列图，使用GCN进行聚合，然后使用注意力机制对目标局部邻居进行加权
- KDD '21, [Dual attentive sequential learning for cross-domain click-through rate prediction](https://dl.acm.org/doi/pdf/10.1145/3447548.3467140)
    - *如何同时提升双域的推荐效果*
    - 共享潜在空间，采用度量学习的方式拉近相似物品的距离
    - 双重注意力机制同时关注两个域，给两个域共同加权打分
- KDD '22, [Contrastive cross-domain recommendation in matching](https://dl.acm.org/doi/pdf/10.1145/3534678.3539125)（CCDR）
    - *试图解决跨域中的稀疏性和流行度偏差*
    - 对每个item采样子图，进行域间和域内的对比学习
    - 非序列问题
- TKDD '22, [Mixed Information Flow for Cross-domain Sequential Recommendations](https://arxiv.org/pdf/2012.00485.pdf)
    - *解决跨域推荐中的知识流动问题*
    - 设计行为转移单元抓取适宜跨域传递的用户行为；设计知识转移单元在知识图谱上进行知识聚合
- TKDE '22, [Parallel Split-Join Networks for Shared-account Cross-domain Sequential Recommendations](https://arxiv.org/pdf/1910.02448.pdf)
    - *解决SCSR的问题*，是π-Net的升级版
    - 与之前相比，这次更加倾向于“分割”+“融合”，编码之后，先对不同用户行为进行分割，然后对跨域进行融合（其实和之前的方法感觉还是蛮像的）
- TKDE '22, [Reinforcement learning-enhanced shared-account cross-domain sequential recommendation](https://arxiv.org/pdf/2206.08088.pdf)（RL-ISN）
    - *也是研究SCSR问题，考虑用户兴趣可能是会随领域改变的，同时会受到领域混杂信息的影响*
    - 首先利用全连接层进行聚类找出不同的用户行为模式，然后从序列中精炼出值得跨域的部分，使用强化学习来给传递的信息打分，最终学会一个良好的跨域推荐器
- MM '22, [DDGHM: dual dynamic graph with hybrid metric training for cross-domain sequential recommendation](https://dl.acm.org/doi/pdf/10.1145/3503161.3548072)（DDGHM）
    - *利用跨域辅助信息解决数据稀疏性问题*
    - 构造双动态图：局部有向图和全局有向图各自捕获域内和全局信息，使用门控＋注意力机制进行集成
    - 使用协同度量学习保持相似项目对齐；使用对比度量学习保证不同表征分布的一致性
- TNNLS '22, [Time interval-enhanced graph neural network for shared-account cross-domain sequential recommendation](https://arxiv.org/pdf/2206.08050)（TiDA-GCN）
    - *研究SCSR问题，目前方法对实体间关系捕获能力弱、忽略了显式的跨领域图结构、未建模点击序列内的时间间隔*
    - 这是DA-GCN的后续工作，考虑了DA-GCN没能考虑的项目间时间间隔问题
    - 设计一个考虑了顺序和时间间隔的图，同时建立账户模拟自注意力感知
- WSDM '22, [RecGURU: Adversarial learning of generalized user representations for cross-domain recommendation](https://dl.acm.org/doi/pdf/10.1145/3488560.3498388)（RecGURU）
    - *解决跨域迁移学习中用户重叠少的情况下的*
    - 在域内进行序列建模，使用自编码器进行编码
    - 分别在域内和全局应用一个解码器进行解码，引入对抗神经网络来保证全局解码器不会对某个域有偏重
- CIKM '22, [Contrastive Cross-Domain Sequential Recommendation](https://arxiv.org/pdf/2304.03891.pdf)(C2DSR)
    - *两个域的序列可能共同反映用户兴趣，这可能在单域是难以被感知的*
    - 具体而言：根据域X、域Y、域X+Y，先做embedding，然后用GNN进行聚合，最后过一个多头注意力完事
    - 利用之前的表征，生成“域”的表示，可以生成单域、跨域、随机跨域等表征，从而进行对比学习
- WWW '23, [Joint Internal Multi-Interest Exploration and External Domain Alignment for Cross Domain Sequential Recommendation](https://dl.acm.org/doi/abs/10.1145/3543507.3583366)（IESRec）
    - *解决用户多兴趣难以提取、域间用户/项目不重叠、信息难以迁移的问题*
    - 在用户多兴趣提取方面，使用ITOT方法识别，使用AUGRU方法聚合；在域间对齐方面，使用FGWD进行对齐
- JCST '23, [Sequential recommendation via cross-domain novelty seeking trait mining](http://jcst.ict.ac.cn/fileup/1000-9000/PDF/2020-2-8-9945.pdf)
- arxiv '23, [Triple Sequence Learning for Cross-domain Recommendation](https://arxiv.org/pdf/2304.05027)（Tri-CDR）
    - *传统CDR容易忽略用户的全局偏好的信息混杂行为*
    - 同时考虑源域、目标域、混合域，分别对三个域序列建模、使用跨域注意力机制加权、使用跨域对比学习生成结果
- TKDD '23, [Sequential and Graphical Cross-Domain Recommendations with a Multi-View Hierarchical Transfer Gate](https://dl.acm.org/doi/pdf/10.1145/3604615)（SGCross）
    - *探究跨域多类型多行为信息传递，利用辅助域信息缓解稀疏性问题*
    - 同时处理三种信息：用户属性信息、单用户交互序列、全局交互图，保证多种信息的融合
    - 使用序列方法Bi-GRU捕获域内动态偏好，使用图方法GCN捕获域内个人偏好，使用多视图分层门单元捕获协作信息
- TCSS '23, [CDRec-CAS: cross-domain recommendation using context-aware sequences](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10012386)
    - *为了充分利用跨域知识的同时减少假信息的流通，同时考虑跨域推荐和上下文感知学习*（这里的上下文信息是否可以理解成属性信息？）（这个属性信息在推荐中亦需要考虑）
    - 整体上基于协同过滤，对于序列内容使用序列规则挖掘(SRM)和LSTM，为了更好地推荐，引入上下文信息。为了引入域间信息，进行属性信息匹配（真的没找到到底采用了什么具体方法进行匹配）
- SIGIR '23, [Beyond the Overlapping Users: Cross-Domain Recommendation via Adaptive Anchor Link Learning](https://dl.acm.org/doi/pdf/10.1145/3539618.3591642)
    - *考虑非同一自然人假设（考虑用户可能在不同域展现出不同的倾向性）*
    - 三个模块：域内兴趣GNN聚合、基于域相关性的推理模块、域间信息传递。
    - 利用信息最优传递策略避免域间信息传递的噪声（但是序列无关）
- SIGIR '23, [AutoTransfer: Instance Transfer for Cross-Domain Recommendation](https://dl.acm.org/doi/pdf/10.1145/3539618.3591701)
    - *过去的跨域方法与RS模型高度相关*
    - 首先根据RS反馈从源域搜索合适的数据实例，然后将精选的数据与目标域数据结合，生成“新目标域”，再利用新数据重新训练RS模型
    - 但是从实验结果来看一般提升不大，AUC提升不到1%
- SIGIR '23, [M2GNN: Metapath and Multi-interest Aggregated Graph Neural Network for Tag-based Cross-domain Recommendation](https://arxiv.org/pdf/2304.07911.pdf)
    - *解决文本信息短和跨域噪声问题*
    - 使用元路径，在源域先将文本提取成兴趣再转移能取得更好的结果

\*motivation用*斜体*表示
- CIKM '23，以下只能查看摘要，只能看看趋势
    - Diffusion Cross-domain Recommendation：使用扩散模型在目标域生成用户嵌入
    - Disentangling Temporal Evolution in Frequency Domain for Sequential Recommendation：在频域进行对用户历史序列的解纠缠，之后进行融合等操作
    - A Cross-Domain Model with Two Pre-Training Tasks for Serendipity Recommendations：建模用户临时起意的特殊兴趣
    - Sequential recommendation via an adaptive cross-domain knowledge decomposition：将两个域的行为用时间戳对齐，引入因果学习进行消歧
    - Multi-domain Recommendation with Embedding Disentangling and Domain Alignment：解缠分辨域内知识和域间知识，域对齐解决重叠量少问题
    - TPUF: Enhancing Cross-domain Sequential Recommendation via Transferring Pre-trained User Features：利用时序特征映射单元和对抗训练提升跨域序列效果
    - Cracking the Code of Negative Transfer: A Cooperative Game Theoretic Approach for Cross-Domain Sequential Recommendation：通过评判边际点对最终结果的影响来决定是否保留


#### 去噪问题
- SIGIR '22, [Self-Guided Learning to Denoise for Robust Recommendation](https://arxiv.org/pdf/2204.06832.pdf)
    - 现有的推荐系统通常难以对难样本(hard clean interactions)（并非噪声，但是具有较大损失值的样本）进行处理
    - 文章认为模型学习分为记忆期和精调期，前半部分会容易学到一些干净数据的知识（可能是因为loss整体较大的缘故），后半部分容易受到噪声影响，故需要去噪工作（这个想法源自对训练结果的观察，前期平稳上升，后期波动，所以认为前期学到的是纯净知识，可以用来指导后面的去噪，怎么说呢，存疑）
    - M_t是被记忆的交互，D是所有交互
    - 基于元学习思想，对于噪声去除的g(f(x))交替优化内层的具体模型f()和外层的噪声检测g()（g为MLP）（优化g时，用的是已记忆的数据；优化f时，用的是全部训练集）
- RecSys '22, [Denoising Self-Attentive Sequential Recommendation](https://dl.acm.org/doi/pdf/10.1145/3523227.3546788)（原来标题的意思就是Denoising SASRec）
    - 为每个自注意力层添加一个可学的二值掩码，使与任务无关的项注意力得分为0（按他的说法，之前的方法(如Star Transformer, Sparse Transformer, Longformer, BigBird)也有为transformer引入稀疏性的（以及存在sparsemax来取代softmax引入稀疏性的方法，但是经查，sparsemax常用于finetune阶段防止过拟合，因为其自身的稀疏性在学习阶段会导致学习不充分），那这么看其实这也是一种引入稀疏性的方式）
    - U是user，I是item，S是用户行为序列，$S^U_t\in I$，每次都用前面的所有内容预测下一个item
    - 因为0-1分布没法求导进行训练，所以写成伯努利分布的形式
    - 其实相当于一个可学的dropout
- WWW '22, [Filter-enhanced MLP is All You Need for Sequential Recommendation](https://arxiv.org/pdf/2202.13556.pdf) 
    - 使用滤波器，证明滤波器对多行为是有意义的，然后魔改MLP，transformer或者别的什么点
    - 深度网络，如transformer和RNN，考虑所有的item，倾向于过拟合，而实验证明了滤波器展现出的性能


#### OOD问题
- MDPI '22, [Out-of-Distribution (OOD) Detection Based on Deep Learning: A Review](https://www.mdpi.com/2079-9292/11/21/3500/htm)
    - 可以在某种程度上把OOD问题看作一个二值分类问题
    - 分为有监督、半监督和无监督
    - 方法分为model-based, distance-based, density-based
        - model-based: arxiv'18, [Learning Confidence for Out-of-Distribution Detection in Neural Networks](https://arxiv.org/abs/1802.04865)
            - 利用神经网络计算置信度的方式检测OOD问题
            - 对于图像，在正常的神经网络中加入一个简单的全连接网络，利用全连接网络给当前样例打分，分数就是置信度，在主模型最终生成结果后乘以该置信度
            - 缺点是仅使用全连接网络能不能真的很好地提取特征存疑，同时存在负标签过拟合问题，对离群点效果不好
        - model-based: ICLR'18, [Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks](https://arxiv.org/abs/1706.02690)
            - 类似地，利用神经网络计算温度系数来检测OOD问题
            - 对于图像，首先利用网络生成温标，然后将温标最大值作为扰动加到输入中。
            - 由于年代较早，所以使用的模型也比较早，也是同期的DenseNet和WideResNet那一套
        - distance-based: arxiv'21, [Joint Distribution across Representation Space for Out-of-Distribution Detection](https://arxiv.org/abs/2103.12344)
            - 通过处理DNN隐藏层之间的变量的联合分布，来判断是否有OOD数据（OOD数据通常分布较为极端，远离数据中心点）
        - density-Based: NIPS'20, [Energy-based Out-of-distribution Detection](https://arxiv.org/abs/2010.03759)
            - 使用能量评分(energy score)进行OOD检测
            - 能量模型是一个经典模型，将能量标量分配给每一个点
            - 基于能量机制作分类，事实证明效果超过了softmax

#### 广泛调研CVPR/ACL
- cvpr主要包括检测、分割、目标跟踪、图像处理、图像生成等，有点找不准方向
- ACL '22, [Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network](https://aclanthology.org/2022.acl-long.124.pdf)
    - 本意为检测图像+文本内容下的讽刺表达（反讽）
    - 最开始，只是将文本和图像分别通过预训练的模型进行embedding，然后将词和图像patching看作节点作图
    - 句子内，建立句内影响树，有就是1。文本与图则将图块转化为形容词+名词，利用情感分析表进行对照，生成相关分数（文本与名词的相似度乘文本与形容词的不相似度）
    - 生成图表征以后，与原有的所有embedding作attention，从而得到最终表征，然后过softmax得到讽刺程度
- ACL '22, [MINER: Multi-Interest Matching Network for News Recommendation](https://aclanthology.org/2022.findings-acl.29.pdf)
    - 本文目标是提取用户的多意图兴趣，进行新闻推荐，预测用户对目标news的兴趣程度
    - 非常朴素的思想，首先把新闻用bert编码，然后把用户编码成K个兴趣（使用注意力机制+标签相似度）
    - loss_1：兴趣的表示之间的相似度，尽量拉开不同兴趣之间的距离
    - loss_2：生成每个兴趣对目标物品的表征，使用各种方法进行加和（从直接加到target-aware注意力），使用NCELoss
    - 加权融合loss，来达到多兴趣建模目的。
- ACL '22, [MTRec: Multi-Task Learning over BERT for News Recommendation](https://aclanthology.org/2022.findings-acl.209.pdf)
    - 类似于上面那篇，但是使用了多任务方法
    - 在主任务之外设计命名实体识别和情感分类任务，利用法线法优化

#### 多行为推荐方法（时间排序）（接下来用问题进行分类）
- 早期
    - KDD '08: [Relational learning via collective matrix factorization](https://dl.acm.org/doi/10.1145/1401890.1401969) 
        - 使用多个矩阵分解
        - **存在问题：早期的多行为方法，非常原始，也没有使用深度网络**
    - KDD '16: [An Empirical Study on Recommendation with Multiple Types of Feedback](https://dl.acm.org/doi/abs/10.1145/2939672.2939690) 
        - 评测了模型组合、贝叶斯推理和联合训练的效果，最终选择模型组合法
        - **存在问题：方法比较生硬，且组合模型开销较大**
    - WWW '17: [Neural collaborative filtering](https://arxiv.org/abs/1708.05031)
        - 使用神经网络改写MF的内积部分，考虑用户辅助行为进行建模
        - **存在问题：缺乏前后行为语义**
        - ICDE '19: [Neural Multi-Task Recommendation from Multi-Behavior Data](https://arxiv.org/abs/1809.08161v2)（多任务，所以联合优化）（NMTR
        - 解释不同类型行为间的级联关系，用户在多行为共享嵌入
        - 神经协同过滤；基于多任务行为进行联合优化（每个行为的优化视为一项任务）；为每个行为学习数据依赖的交互功能；级联多种行为
        - **存在问题：处理多类型交互时较为独立和局部化**
    - KDD '19: [Buying or Browsing? : Predicting Real-time Purchasing Intent using Attention-based Deep Network with Multiple Behavior](https://dl.acm.org/doi/10.1145/3292500.3330670)（DIPN）
        - 利用分层注意力机制来学习多行为数据
        - **存在问题：仅考虑低级的相关性，未考虑不同行为的重要性区别**
- 2020
    - SIGIR '20: [Multiplex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network](https://arxiv.org/abs/2110.04002)（MATN）
        - transformer捕获多行为间关系，然后门控聚合
        - **存在问题：不同用户的进行不同的行为意图是有区别的，这方面缺乏考虑**
    - AAAI '20: [Efficient Heterogeneous Collaborative Filtering without Negative Sampling for Recommendation](http://www.thuir.cn/group/~mzhang/publications/AAAI2020-Chenchong.pdf) 
        - 假定了行为的权重（多任务）
        - 一种高效异构协同过滤，以一种迁移方式将各种行为的预测关联起来，同时避免负采样
        - **存在问题：忽略对行为强度的建模导致信号丢失；没有考虑多种行为的语义**
    - SIGIR '20: [Multi-behavior Recommendation with Graph Convolutional Networks](https://dl.acm.org/doi/abs/10.1145/3397271.3401072)（MBGCN）
        - 利用统一的图解决问题，建立多行为图卷积网络，不同行为表示为图的多种边
        - **存在问题：缺乏对高阶行为相关性的建模**
    - CIKM '20: [Multiplex Graph Neural Networks for Multi-behavior Recommendation](https://dl.acm.org/doi/abs/10.1145/3340531.3412119)（MGNN）
        - motivation：之前的假设“用户不同行为应当按照固定顺序进行”过强，实际上许多行为发生的顺序因人而异
        - 使用Multiplex Graph Neural Network进行建模
        - 使用GNN对聚好类的图进行embedding
        - 是CIKM的短文，有点水
- 2021
    - SIGIR '21: [Graph Meta Network for Multi-Behavior Recommendation](https://dl.acm.org/doi/abs/10.1145/3404835.3462972)（这个是多行为优化）
        - 元学习考虑个性化特定交互行为异质性编码；元图神经网络捕获多种多行为模式；元预测网络捕捉多任务下跨行为依赖
    - AAAI '21: [Knowledge-enhanced hierarchical graph transformer network for multi-behavior recommendation](https://ojs.aaai.org/index.php/AAAI/article/view/16576/16383)（KHGT）
        - 贡献：处理不同类型行为依赖；考虑知识感知项目关系；多类型交互的动态特征
        - 方法：使用图神经网络、注意力机制、门控神经网络，学习用户-项目，项目-项目，潜在交互关系
    - ICDE '21: [Multi-Behavior Enhanced Recommendation with Cross-Interaction Collaborative Relation Modeling](https://arxiv.org/pdf/2201.02307.pdf)（GNMR）
        - 很朴素，先得到行为内表征，然后分别对每个行为的每个维度加权
        - 对于不同类型交互之间的关系，则使用注意力机制打分
        - 很朴素，各自计算以后，计算聚合权重再融合
    - ICDM '21, [Hyper meta-path contrastive learning for multi-behavior recommendation](https://arxiv.org/abs/2109.02859)
        - 考虑用户在买不同类型的东西的时候会采用不同的行为模式，建模用户行为间的相关性
        - 把用户行为做成超图，进行对比学习对用户表征
- 2022
    - WSDM '22, [Contrastive Meta Learning with Behavior Multiplicity for Recommendation](https://arxiv.org/abs/2202.08523)（CML）
        - 新建一种多行为模式来强调多样化行为，并缓解稀疏性；对比学习；元学习
    - DASFFA '22, [Multi-view Multi-behavior Contrastive Learning in Recommendation](https://arxiv.org/pdf/2203.10576.pdf)
        - motivation: 对行为间的粗粒度共性进行建模，考虑细粒度上的差异，同时考虑序列的局部特征和全局图的全局特征
        - 使用三个对比学习分别捕获以上的三种倾向（似曾相识）
        - 具体而言，个体行为序列建模、全体行为图建模，都去做CL，最后融合生成表征
    - IJCAI '22, [Self-supervised graph neural networks for multi-behavior recommendation](http://shichuan.org/doc/134.pdf)（S-MBRec）
        - motivation: 除去多种行为间的差异，他们也有相当的共性值得挖掘
        - 为每个子图进行GCN，然后分为两个任务：监督任务和自监督任务
            - 监督任务：学习行为的强度权重融合嵌入
            - 自监督任务：利用对比学习捕获行为间的共性
    - TKDD '22, [MBN: Towards Multi-Behavior Sequence Modeling for Next Basket Recommendation](https://dl.acm.org/doi/10.1145/3497748)
        - 篮子推荐也会受到多行为数据的影响，因此从多行为篮子序列中学习
        - 分别学习篮内表示、时序多行为元表示和循环项目模式
    - arXiv'22, [Multi-Behavior Dynamic Contrastive Learning for Recommendation](https://openreview.net/pdf?id=ykO+pK9O5qYv)
        - 学习用户多行为的异质图
        - 利用对比学习建模用户的细粒度长期偏好
        - 写的不太好
    - WSDM'23: [Knowledge Enhancement for Contrastive Multi-Behavior Recommendation](https://dl.acm.org/doi/abs/10.1145/3539597.3570386)（KMCLR）
        - 为充分利用用户多行为信息，解决两个问题：目标行为稀疏、用户行为模式不同
        - 利用对比学习捕获粗粒度共性和细粒度差异；利用知识图谱进行知识增强
    - TOIS '23, [Coarse-to-Fine Knowledge-Enhanced Multi-Interest Learning Framework for Multi-Behavior Recommendation](https://dl.acm.org/doi/10.1145/3606369)（CKML）
        - 不同的行为可能反映用户不同的兴趣，进行多兴趣建模
        - 对兴趣进行粗粒度提取和细粒度关联

#### 因果相关的多行为推荐
- WWW'22，[A Model-Agnostic Casual Learning Framework for Recommendation Using Search Data](https://arxiv.org/abs/2202.04514)
    - 提出一个不可知框架
    - 利用因果分析，将搜索行为嵌入为工具变量，用以重构推荐中的原始嵌入向量，避免干扰因子的作用
    - 由于搜索引擎的数据是user-query-item-click四元组，所以可以通过数据召回每一个被点击item前的query，然后利用bert等方法将文本转化为向量；对于用户user，则利用其浏览历史的item构建。
- TOIS'23, [Enhancing Recommendation with Search Data in a Causal Learning Manner](https://dl.acm.org/doi/10.1145/3582425)
    - 上面工作的延续，
- arxiv'23，[Zero-shot causal learning](https://arxiv.org/pdf/2301.12292.pdf)（CAML）
    - 本文试图在零样本环境下探究干预因素(intervention)的影响（即新干预对新样本的影响），因此需要将新干预想办法与旧干预对齐
    - CATE: Conditional Average Treatment Effects
    - W:干预特征，X:用户特征
    - 模型包括三个部分：训练单独的元模型以学习CATE，并试图推广到尚未学过的任务上；直接利用intervention的伪结果生成影响；利用大量的离散任务提升效果
    - treated是有intervention的，control是没有的
    - 允许多个W在同一个i中，但是只是将它们加和
    - 优化一个无偏、有噪声的$\tao_i^{\{j\}}$（使用RA-learner方法生成，是一种回归方法，具体不太懂），代表CATE的结果，把这称为伪结果
    - 利用伪结果对对(w,x)分析的模型进行优化
- AAAI'23, [Learning Instrumental Variable from Data Fusion for Treatment Effect Estimation](https://arxiv.org/pdf/2208.10912.pdf)
    - 完全体见此[网址](http://sias.zju.edu.cn/2023/0513/c57510a2756778/page.htm)
    - 每个数据里包括$t, x, y, \e$，其中t完全由x和e转化而来
    - x->r->t，用z+r重建t，r重建x作为正则化项
- arxiv'23, 综述[Causal Inference for Recommendation: Foundations, Methods and Application](https://arxiv.org/pdf/2301.04016.pdf)
- ICDE '22, [Sequential Recommendation with User Causal Behavior Discovery](https://arxiv.org/abs/2204.00216)
    - 使用聚类将物品间的因果关系转化为类间的因果
    - 将因果转移矩阵乘到正常模型的embedding相乘过程中
    - 通过人工标注数据证明了因果的可解释性





#### 搜推融合
- wsdm22，[Joint Learning of E-Commerce Search and Recommendation](https://dl.acm.org/doi/abs/10.1145/3488560.3498414)
    - 构造统一的图来解决是否有显式查询的差异，将用户和物品的交互作为边（如果为查询则将word序列作为query，如果为点击则置空）
    - 将GNN过程改写，在对总目标$n_t$的下游节点$n$扩展邻居节点时，同时考虑$n$的父节点$n_p$和子节点$n_n$，并且融合两个节点之间的查询关系$q$.
    - 缺点是没有使用序列方法，缺乏对时间戳的进一步利用
- cikm21，[User: A Unified Information Search and Recommendation Model Based on Integrated Behavior Sequence](https://arxiv.org/abs/2109.15012)
    - 将搜索和推荐中的行为整合到一个异构的行为序列中，具体而言，序列为$\{B_1, B_2, Q_1\{C_1, C_2\}, B_3, ...\}$，其中$B$为浏览点击，$Q$为查询query，$C$为查询后的点击
    - 从整合序列中挖掘用户兴趣
    - 缺点是序列较长，难以处理，以及并未考虑跨场景的方法
    - 流程分为四块：
        - Text Encoder：将文本转换为embedding，由于这一部分可替方法很多，所以略过
        - Session Encoder：
            - 最后一步的预测环节embedding，如果是查询就把query给编码了，否则使用user embedding
            - 对于search的embedding，需要同时考虑search query和所有browsed articles（合在一起），二者经过两层神经网络结合之后输出（对于待排序的文档也可以这样做）
        - History Encoder：利用最后一个session的/总的最后一个输出作为对应的待预测问题的embedding
        - Unified Task Framework：同时计算短期、长期的交叉相似性（这样一来就是2*2=4种相似性），加上利用KNRM计算的搜索-文档相似性和基于相似性的特征，共六种，利用MLP合成。
- emnlp19，Neural News Recommendation with Heterogeneous User Behavior
    - 利用CNN从新闻标题中学习新闻的表示，利用注意力选择重要词汇
    - 多视图学习框架：从异构行为（如搜索、点击、浏览）中学习用户统一表示，分别对新闻、查询query、查询中的单词建模
    - 目的：利用用户行为增强推荐
- CIKM21，Self-Supervised Learning on User's Spontaneous Behavior for Multi-Scenario Ranking in E-Commerce
    - 对用户自发行为（搜索行为）进行预训练
- WWW2021, [Learning a Product Relevance Model from Click-Through Data in E-Commerce](https://arxiv.org/abs/2102.07098v1)
    - 显示与用户意图不匹配
    - 利用用户点击来学习，但是用户点击行为是嘈杂的
    - 利用用户对搜索结果的点击，来判断搜索结果的相关性
    - 通过注意力机制来提取产品和查询信息
- Pre-Print2022, Amazon, [Efficient and effective training of language and graph neural network models](https://arxiv.org/abs/2206.10781)
    - 基于GNN和BERT联合微调，但是或许可以考虑此后使用prompt相关方法改良？总之还是往下看
    - 在本文中，是这样一张图：节点表示query和item，边表示点击/购买（这种数据形式为[Amazon KDD Cup 22'](https://www.aicrowd.com/challenges/esci-challenge-for-improving-product-search)，认为节点包含短文本信息，而边不包含（当然也有别的数据集，因为本文算一个观察，讨论的是通用的方法），本文正是要探寻把节点文本嵌入语言模型的方法
    - 三个预测任务：预测边的存在，预测节点分类，预测边的类型
    - 直接使用语言模型的两个问题：嵌入不准确、嵌入效率低
        - 嵌入不准确问题：使用对比学习对LM进行微调，然后冻住LM对gnn进行预热
        - 嵌入效率低问题：随机小批量采样优化LM，剩余时间冻住LM；提前进行整体的文本嵌入并缓存，代价是准确性降低；联合负采样，重用负的边的例子；
    - 实验配置：
        - GNN：同质图：GraphSAGE，异构图：RGCN
        - LM：BERT，用对比学习train一下
    - 实验结果：
        - 节点分类：普通MLP+finetune和GNN+无finetune效果相当，说明初始的BERT不适合图结构；对BERT作对比学习也能显著提升效果
        - 链路预测：BERT对比学习带来了及其显著的提升；热启动带来了相当的优势；此外，热启动速度很快
        - 链路分类：首先，GNN对于链路分类效果的确提高，但是使用调过的BERT，却导致了效果下降，这是一个观察。
        - 推荐效果：在私有数据集进行训练，相当于只考虑链路分类中的E，结果效果好了，现在看可能是因为amazon比赛数据集的问题
- SIGIR '23, [When Search Meets Recommendation: Learning Disentangled Search Representation for Recommendation](https://arxiv.org/pdf/2305.10822.pdf)
    - 对点击和搜索都进行相似和不相似的切分
- CIKM '22, [Query-Aware Sequential Recommendation](https://dl.acm.org/doi/10.1145/3511808.3557677)

- SIGIR2020, [Knowledge Enhanced Personalized Search](https://dl.acm.org/doi/10.1145/3397271.3401089)
    - 你先别急，这是做知识图谱的，先往后放放

- Keyword-Based Knowledge Graph Exploration Based on Quadratic Group Steiner Trees（在复杂知识图谱上的搜索）
- FedPS: A Privacy Protection Enhanced Personalized Search Framework（个性化搜索中的隐私泄露问题）
- Attentive Long Short-Term Preference Modeling for 5. Personalized Product Search（用长短期记忆网络辅助个性化搜索）
- Embedding-based Retrieval in Facebook Search（facebook上的个性化搜索）
- Modeling User Behavior with Graph Convolution for Personalized Product Search（对用户连续行为图进行建模，挖掘用户偏好（可这和搜推有什么关系呢？）
- CL4CTR: A Contrastive Learning Framework for CTR Prediction（进行特征表示工程）
- Efficient and effective training of language and graph neural network models（GNN结合大规模语言模型做推荐，先看看吧）
- ReprBERT: Distilling BERT to an Efficient Representation-Based Relevance Model for E-Commerce（接下来的四篇都看过了，都旨在解决搜索结果与用户意图不匹配的问题）
- Graph-based Weakly Supervised Framework for Semantic Relevance Learning in E-commerce
- Learning a Product Relevance Model from Click-Through Data in E-Commerce
- Weakly Supervised Co-Training of Query Rewriting and Semantic Matching for e-Commerce

- 师兄的代码阅读
- [ZhihuRec](https://github.com/THUIR/ZhihuRec-Dataset)数据集，有100M，20M，1M三档，包括了用户搜索、点击、阅读的行为，以及问题、答案的特征



#### in-context learning
- 单开一条，说明一下情况，现在是2023年3月9日，有一个美团的项目申请，不大，但是可以使用大模型，这里试图使用in-context learning，现在提出一个小想法，就是利用大模型作为一个随时取用的知识库，将大模型完全冻结，然后考虑推理过程，由于多步推理类似多层模型，故而堆叠很多层次的prompt核，每个核生成了prompt以后，就交给大模型作表示，然后再将表示送往下一层的prompt核，这样堆叠交替进行，从而进行深度推理。接下来调研相关文献中。
- [A Survey on In-context Learning](https://arxiv.org/abs/2301.00234)
    - 一切的起点，作为2023年1月的综述，以下数篇皆出自这里
- [Complexity-Based Prompting for Multi-Step Reasoning](https://arxiv.org/abs/2210.00720)
    - 预印本，也在做大模型推理
    - 解决的是NLP领域问题，研究的问题类似于求解数学题
    - CoT问题，即chain-of-thought，为大模型提供推理链示例让大模型进行推理
    - 采用复杂的prompt交给语言模型，从而提升推理能力和泛化能力（观察所得）
- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)
    - 经过实验证明，当对LLM提供CoT时，LLM的效果是好的，即使面对Few-Shot，也有较好表现
    - 但是面对零样本问题，就不尽人意，但如果给它一句“Let's think step by step.”就会好很多。
- [Automatic Chain of Thought Prompting in Large Language Models](https://arxiv.org/abs/2210.03493)
    - 也是CoT问题，这一次设计一个自动的CoT生成器
    - 发现零样本的方法并不好，然后手动标注方法太贵，所以聚类之后选出代表性问题进行启发式生成
- [Measuring and Narrowing the Compositionality Gap in Language Models](https://arxiv.org/abs/2210.03350)
    - 通过自问自答的方式提升大模型推理能力
    - 使用一个多跳推理数据集，比如“贾斯汀比伯出生那年谁赢得了xx比赛冠军？”
    - 目的是解决搜索引擎中的此类问题
    - 方法是在数据集中为一个这种多跳问题构建多个子问题，引导大模型进行理解。
- [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://arxiv.org/abs/2205.10625)
    - 把问题拆成一个一个小问题，这些小问题交给预训练模型回答，每次回答完$q_k$得到答案$a_k$，都把$q_k, a_k$都放到$q_{k+1}$中。
    - 这是一个两阶段问题，第一阶段由LLM将大问题拆成若干小问题，第二阶段迭代求出最终结果。（没涉及什么模型，感觉像一个观察）
- [Iteratively Prompt Pre-trained Language Models for Chain of Thought](https://arxiv.org/abs/2203.08383)
    - 设计一个迭代上下文推理感知器，每次prompter基于$\{q,c_1,..., c_{n-1}\}$生成一个$p_n$，提交给LLM生成$c_n$（可恶这不是和一开始的想法一样嘛）
- **目前推荐中的因果推理工作可以分为以下三类，即针对数据偏差的因果推理推荐算法、针对数据缺失和噪声的因果推理推荐算法以及超越推荐精度的因果推理推荐算法。**
- [GPT Understands, Too](https://arxiv.org/abs/2103.10385)
    - 这是一种Pattern-Exploiting Training(PET)，想法是通过构建模板(Pattern)的方式调优BERT类或GPT类的模型，具体而言，**加入补充信息&构建完形填空**，从而提升**小样本/零样本**效果。
    - 这是一个观察：虽然使用这种前缀调优法主要是为了适应小样本，并且节省空间和时间，但是即便在样本充足、开放全部参数调优的情况下，它仍然有优势，可能是因为任务目标和预训练任务更为契合。
    - 
- [A Survey of Graph Prompting Methods: Techniques, Applications, and Challenges](https://arxiv.org/abs/2303.07275)
    - 这一切发生的太快了，这么快已经产生了图的prompt learning综述
    - prompt生成大体分为3种：
        - 手动提示设计：基于下游任务的特定人类知识创建模板
        - 离散提示设计：用输入样本的个性化邻域和边填充模板
        - 连续提示设计：根据模板的表示向量生成模板

#### 可信GNN
- arXiv2022, A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability
    - Privacy, Robustness, Fairness, Explainability四个角度较为系统介绍可信GNN
- NIPS2019, Gnnexplainer: Generating explanations for graph neural networks
    - GNN缺乏透明度，是因为它的预测不容易得到人类理解的解释
    - 解释GNN可以增强信任、提高公平性、保护数据隐私、便于使用者纠错
    - 通过构建一个最相关子图的方式解释做出分类的原因
- NIPS2020, Parameterized explainer for graph neural network
    - 之前的工作是对单个分类结果的解释，当解释整个模型的多个结果时性能很差
    - 提出一个高效的对全部分类结果/对图分类结果的解释
    - 利用节点表示和原始图来计算边分布的潜在变量

#### 杂
- KDD2018, Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts
- IEEE2020, Scenario-aware and Mutual-based approach for Multi-scenario Recommendation in E-Commerce
- CIKM2021, One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction
- CIKM2022, [Tiger Transferable Interest Graph Embedding for Domain-Level Zero-Shot Recommendation](https://dl.acm.org/doi/abs/10.1145/3511808.3557472)
- KDD2022, Contrastive Cross-domain Recommendation in Matching
- SIGIR2020，CATN: Cross-Domain Recommendation for Cold-Start Users via Aspect Transfer Network
    - 利用注意力机制提取用户细粒度偏好，迁移到目标域
    - 同时利用用户评论、商品评论和相似用户评论，结合后预测CTR
    - 源域和目标域同时向对面进行迁移
- A Survey for In-context Learning
    - 分为两阶段：一阶段训练模型的ICL能力，二阶段根据任务的演示进行预测
- [Personalized Prompts for Sequential Recommendation](https://arxiv.org/abs/2205.09666)
    - 利用预训练建模，缓解现实世界中的数据稀疏问题
    - 使用提示调优（Protempt-tuning）来缓解预训练目标和下游目标的差距并减少数据使用量
    - 挑战
        - 如何转换问题？
        - 如何构建适合推荐的提示？
    - 将用户切为warm和cold，分别用来预训练和调优，切分依据是历史序列长度
    - SASRec作为预训练模型，输入为用户点击序列，预测任务是预测用户的下一个点击
    - 第一步：使用MLP基于用户特征生成前缀的提示序列
    - 第二步：进行调优，light版本只调整prompt-tune的参数，快但效果不好；full版本连着预训练模型一起调优，效果upup
    - 加入对比学习元素，把user embedding和行为序列都进行随机mask，并且作对比学习，预防over fitting
- Virtual Node Tuning for Few-shot Node Classification(师兄审的一篇稿)
    - 对于预训练过的graph transformer，利用在嵌入空间生成虚拟节点的方式进行软提示
- Generative Recommendation: Towards Next-generation Recommender Paradigm
    - 在结合用户历史交互序列（即用户偏好）的情况下生成、处理视频流的模型，是一个生成式模型（视频版chatgpt？）
- ICLR'23, [LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation](https://arxiv.org/abs/2302.08191)
    - 当前存在的问题：
        - 随机的数据增强可能导致数据结构的大改变
        - 现有的对比学习方法与数据分布强相关，易受噪声干扰
        - 存在过平滑问题
    - 采用奇异值分解的方式重构图像，借用图像去噪的一个观点，只保留前$q$大的奇异值，再利用其重构邻接矩阵
    - 目标：
        - 减小过平滑/过拟合
        - 避免图形结构改变
        - 快速

- KDD'22, [Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation](https://arxiv.org/abs/2207.05584)
    - 多行为超图增强的transformer框架
- WWW'23, [Denoising and Prompt-Tuning for Multi-Behavior Recommendation](https://arxiv.org/abs/2302.05862)
    - 多行为建模，考虑点击、加购和购买三者之间的联系
    - 比之过去的多行为建模方法，此方法旨在消除多行为数据中的噪声影响
    - 定义$K$张图，$G^a_{ui}$代表辅助交互，$G^t_{ui}$代表目标交互，希望输入一个$G$，能返回去噪的$G'^a+G^t$
    - 利用Jaccord系数求两个用户的相关性，大于0则在uu图连一条边（这看上去是一种生成uu图的方法）（当然，出处是21年的一篇aaai）
    - 利用用户历史交互，只要用户历史序列点过a再点b，就把ab连上
    - embedding层为每个u、每个i、每个行为都设计一个embedding矩阵
    - aggregation层
        - uu图（无向图）使用GCN
        - ii图（有向图）使用GAT，入图和出图分开
        - ui图使用lightGCN
        - 经典用门聚合
        - 利用embedding重建$G_{ui}$，然后算损失，从属于一个观点：噪声更难以被重建出来
- WWW'23, [Compressed Interaction Graph based Framework for Multi-behavior Recommendation](https://arxiv.org/abs/2303.02418)（华为郭老师项目）
    - 针对多行为推荐问题，使用一种多专家网络+GCN的方式，捕获实例级高阶关系
    - 行为作为“特征”，提供了多种显式交互；行为作为“标签”，可以缓解与隐藏梯度的冲突

- SIGIR'23审稿, Domain-Oriented Knowledge Transfer for Cross-Domain Recommendation
    - 利用跨领域知识图谱迁移；设计一种有效的跨域策略
    - 利用类似KGCN的方式进行节点聚合，但是不知为何Eq(1)只讨论了user，没讨论item
    - 设计了一系列采样策略，分为random、target优先、source优先
    - 挖掘兴趣就是先两层MLP，然后用transformer拿下
    - 跨领域知识图谱是拿现有的知识图谱进行合并得到的
    - 怎么没写另外几个模型的参数，怎么用的模型只有两个是近两年的
- KDD'23审稿, IncMSR: An Incremental Learning Approach for Multi-Scenario Recommendation
    - 用多场景数据train一个统一模型服务所有场景，解决多场景多数据效率问题和数据在时间上的分布关系的问题。
    - 方法：量化场景、时间和时间-场景的pair-wise距离，利用增量模型学习，最后用度量学习（对比学习）进行统一。
    - 等于在处理时间序列？先输入一段序列，然后逐时间步用后续序列来更新模型（增量模型方法）
    - 出现语法错误——把MMoE写成了HMoE（related work部分），没有说明$N_{t,d}$是什么
    - 整体框架上：
        - 基于度量学习想法，学习一个$f$将点映射到表示空间
        - 最小化共享层的场景间距离和跨时间距离，最大化场景特定层的场景间距离和跨场景跨时间距离
        - 预测就使用交叉熵损失
    - 回答三个问题：
        - 模型性能如何——经过比较，优于现有MSR模型
        - 与现有MSR兼容度如何
        - 设计的三种特殊的传递有没有意义
- WSDM22'，[Heterogeneous Graph Contrastive Learning for Recommendation](https://arxiv.org/abs/2303.00995)
    - 异质图的图神经网络
    - 在有元网络的情况下辅助对比学习
    - 简而言之，利用三个图：u-u，u-i，i-i，以u举例，基于单独的u、基于u-i、基于u-u，均生成表征，在有联系的u-u和没联系的u-u之间；在有联系的u-i和没联系的u-i之间 作对比学习。
- arXiv '23, [LLM-Rec: Personalized Recommendation via Prompting Large Language Models](https://arxiv.org/pdf/2307.15780.pdf)
    - 利用输入增强来提高大语言模型个性化内容推荐性能的各种提示策略（所以这里重点放在了输入增强上）
    - 使用基本提示（由大模型自主生成文本增强）；推荐驱动提示（询问大模型如果要推荐的话应该如何增强）；参与指导提示（利用ui二部图和PageRank算法找到最重要的邻居，从而将重要邻居的信息提交模型用来增强）；推荐驱动+参与指导提示
- arXiv '23, [Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://arxiv.org/pdf/2308.09687.pdf)
    - 将思维链改造为思维图，从而为思维提示提供更多可能性
    - 图的节点是LLM生成的各种信息（各种部件），从而能够更加随意地将大模型的子结果进行协同
- ACL '19, [Explicit Utilization of General Knowledge in Machine Reading Comprehension](https://arxiv.org/pdf/1809.03449v3.pdf)（不对，这篇找错了）
    - 关键是知识辅助注意力算法：
        - 坏了，有点没看懂，关键应该是基于每个词的上下文的embedding进行相似度计算得到A值。
- SDM'24审稿, FedDCSR: Federated Cross-domain Sequential Recommendation via Disentangled Representation Learning
    - 需要在保护用户数据隐私的情况下进行跨域推荐
    - 总体而言，还是横向联邦学习那一套，但是最后加了个对比学习
- arXiv '19, [CTRL: A Conditional Transformer Language Model For Controllable Generation](https://arxiv.org/pdf/1909.05858.pdf)（气死，这篇也找错了）
    - 用类别标签控制语言模型生成，类似于prompt。
- 鸾康师姐投的DASFAA'24, Disentanglement-based Adaptive Feature Enhancement Framework for Cross-Domain Recommendation
- WWW'24审稿, Heterogeneous Graph Transfer Learning for Category-aware Cross-Domain Sequential Recommendation
    - 跨域序列推荐中，引入上下文信息，提出类别感知跨域序列推荐
    - 把category作为异构图中间的节点，基于category的相似度/共现情况构建虚拟边
    - 265行，应该是Figure 2(a)
    - 这是怎么缓解两个域数据数量差距太大的问题的呢？以及拓展更多的域并没有带来很大提升。
    - 两边的category应该如何对齐呢？如果缺乏良好的对齐手段，基于category的一系列方法就都退化成了单域方法。
    - 建立这样一个全局图是否开销太大。
    - 文中提出了扩增expand边的方法，但是可以看到，按照文章的说法，图上的聚合是按照这6种元路径进行的，那么扩增的意义是什么呢？
    - 附录中提到，数据处理的时候只保留了在三个域都有交互的user，这使得实验难以证明异构图在275-282行表述的重叠用户少的情况下跨域推荐的效果。
- SIGIR '21, [One Person, One Model, One World: Learning Continual User Representation without Forgetting](https://arxiv.org/pdf/2009.13724.pdf)
    - 为模型进行动态地终身学习表示，从而去除旧任务中不太重要的权重，从而从一个单独的模型扩展到多个任务。
- NIPS '17, [Neural Discrete Representation Learning](https://arxiv.org/pdf/1711.00937.pdf)
  - 最初版本是AE, Autoencoder，从encoder接到decoder，然而问题是解码器只认识特定的编码器训练出的嵌入
  - 然后是VAE，通过将编码向量z约束到标准正态分布，使得任意同样约束到标准正态分布的编码都能解码出实际图片了~
  - VQ-VAE解决了目前VAE输出图片质量不高的问题，实验发现是连续的嵌入向量没有离散的向量表示效果好，应该使用离散的中间向量，所以使用codebook来转换离散向量到连续向量。
- ICDE '23, [Group Buying Recommendation Model Based on Multi-task Learning](https://arxiv.org/pdf/2211.14247.pdf)(复旦大学)
  - 开源代码：https://github.com/DeqingYang/MGBR
  - 这是一个两task任务，一个task是为发起人找到合适的item，一个是为发起人和item组成的对找到合适的参与人，这样对于发起人而言就能同时看到适合的项目和潜在的参与人数，从而提升推荐质量
  - 考虑团购场景中，项目、发起者和参与者的不同，构建三个视图：UI（发起者&item）、PI（参与者&item）、UP（发起者&参与者）
  - 首先分别对这三者进行GCN获得embedding，每个视图能获得两套表征（因为都是二种节点组成的图），据此，可以拼合出三个表征：$e_u = e^{UP}_u \oplus e^{UI}_u$以此类推
  - 然后使用门专家网络聚合，门设计得很复杂，具体去看原论文
- KDD '25审稿, [GenSAR: Unifying Balanced Search and Recommendation with Generative Retrieval](GenSAR)
  - 缺少开源代码，因此模型可能缺乏可复现性
  - 把两个预训练后的embedding送入rq，从而获得共享代码（高层）和底层代码，拼接的embedding并没有经过任何的对齐，这样获得的代码本质上和分开获得代码没有区别，试想若文本相似的item在协同信号并不相似，这种编码方式会导致他们的相似性出现冲突，从而导致两种信息的融合困难
  - 从整体消融和两种信息的消融可以看到，即使消除其中一些模块，或者甚至去掉其中的推荐/搜索的信息，结果仍然非常具有竞争力，值得注意的是，当消融掉推荐/搜索信息的时候，文章的方法已经退化回了常规的生成式推荐，但是效果仍然远超baseline，意味着模型的能力或许来源于更加高质量的大模型backbone或预编码模型，而非本文提出的训练策略。你能否展示对其他工作使用同等大模型进行编码或推理的实验结果对比
  - 你的方法涉及到微调一个大模型进行推理，相比于你进行比较的baseline，这可能引入了极多的参数，并增加了大量额外的时延，这在真实的推荐场景中是难以接受的，你能否给出关于推理时延和参数量的实验？
- KDD '25审稿, [UIMEF: A Non-Learning Embedding Method for Mini-Program Game Advertisements CTR Prediction](UIMEF)
  - 一个数据为中心的特征学习模块，但是不需要输入额外的特征，仅靠交互来进行类似数据预处理的操作，所以可以被认为是一个特殊的嵌入层
  - 纯粹随机分配每个user和item的特征表示，这样可以基于时间衰减和点击/未点击交互来互相学习特征，最终获得较好表示
- KDD ADS '25审稿, [Hardness-aware Privileged Features Distillation with Latent Alignment for CVR Prediction](HA-PFD)
  - 提升CTR预测，使用特权特征蒸馏（有一些特征在线上没法获取/训练/使用，但是又需要，所以用蒸馏蒸到不能用特权特征的模型中
  - 解决针对难度的加权和正负例差异过大的问题
  - 基于学生/教师模型的置信度来进行加权

#### 书
- [A Cookbook of Self-Supervised Learning](https://arxiv.org/abs/2304.12210)
- Science Research Writing for  Native and Non-native Speakers of English 2nd

